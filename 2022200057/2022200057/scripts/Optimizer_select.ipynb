{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d13e594-c694-4eff-b41c-f70a05fc2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56537059-9d1f-47c1-986a-db06e7236163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    'C:\\\\Users\\\\mjy\\\\Desktop\\\\Project_MSCM\\\\INPUT_7.csv',\n",
    "    'C:\\\\Users\\\\mjy\\\\Desktop\\\\Project_MSCM\\\\INPUT_15.csv',\n",
    "    'C:\\\\Users\\\\mjy\\\\Desktop\\\\Project_MSCM\\\\INPUT_30.csv'\n",
    "]\n",
    "\n",
    "# 标签列名\n",
    "label_columns = ['未来7日涨幅']\n",
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc8fe421-6e62-4075-9069-1882ba92dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建包含LSTM和CNN的模型\n",
    "def create_cnn_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cda358a4-f43c-4b0f-aa03-af466cbb1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "WARNING:tensorflow:From D:\\Anaconda-Install\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 8s 100ms/step - loss: 0.6928 - accuracy: 0.5519 - val_loss: 0.6668 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6841 - accuracy: 0.5519 - val_loss: 0.6914 - val_accuracy: 0.5147 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6709 - accuracy: 0.5833 - val_loss: 0.6555 - val_accuracy: 0.5956 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6767 - accuracy: 0.5759 - val_loss: 0.6765 - val_accuracy: 0.5662 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6653 - accuracy: 0.6037 - val_loss: 0.6424 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6460 - accuracy: 0.6130 - val_loss: 0.6532 - val_accuracy: 0.6103 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6399 - accuracy: 0.6204 - val_loss: 0.6261 - val_accuracy: 0.6765 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6096 - accuracy: 0.6574 - val_loss: 0.6186 - val_accuracy: 0.6618 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.5924 - accuracy: 0.7000 - val_loss: 0.6652 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5570 - accuracy: 0.7148 - val_loss: 0.6471 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5444 - accuracy: 0.7130 - val_loss: 0.6364 - val_accuracy: 0.6765 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5341 - accuracy: 0.7481 - val_loss: 0.6425 - val_accuracy: 0.6691 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4832 - accuracy: 0.7648 - val_loss: 0.6380 - val_accuracy: 0.6691 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4573 - accuracy: 0.8056 - val_loss: 0.6452 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4338 - accuracy: 0.8241 - val_loss: 0.6392 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4406 - accuracy: 0.7963 - val_loss: 0.6073 - val_accuracy: 0.7059 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3894 - accuracy: 0.8222 - val_loss: 0.6668 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3840 - accuracy: 0.8222 - val_loss: 0.6123 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.3745 - accuracy: 0.8407 - val_loss: 0.6344 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3589 - accuracy: 0.8333 - val_loss: 0.6068 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3500 - accuracy: 0.8630 - val_loss: 0.6439 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.3406 - accuracy: 0.8574 - val_loss: 0.6032 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2991 - accuracy: 0.8704 - val_loss: 0.6319 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3141 - accuracy: 0.8667 - val_loss: 0.6396 - val_accuracy: 0.7426 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2816 - accuracy: 0.8778 - val_loss: 0.6503 - val_accuracy: 0.7426 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2960 - accuracy: 0.8556 - val_loss: 0.7291 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3107 - accuracy: 0.8759 - val_loss: 0.6075 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2710 - accuracy: 0.8944 - val_loss: 0.6453 - val_accuracy: 0.7353 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2590 - accuracy: 0.9000 - val_loss: 0.6698 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2865 - accuracy: 0.8667 - val_loss: 0.6582 - val_accuracy: 0.7353 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2369 - accuracy: 0.9130 - val_loss: 0.6528 - val_accuracy: 0.7279 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2239 - accuracy: 0.9093 - val_loss: 0.6749 - val_accuracy: 0.7426 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2308 - accuracy: 0.9000 - val_loss: 0.6889 - val_accuracy: 0.7426 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2358 - accuracy: 0.9000 - val_loss: 0.6761 - val_accuracy: 0.7426 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2179 - accuracy: 0.9130 - val_loss: 0.6780 - val_accuracy: 0.7426 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2112 - accuracy: 0.9093 - val_loss: 0.6701 - val_accuracy: 0.7426 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2313 - accuracy: 0.9056 - val_loss: 0.6790 - val_accuracy: 0.7574 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2058 - accuracy: 0.9222 - val_loss: 0.6855 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2123 - accuracy: 0.9056 - val_loss: 0.6754 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2103 - accuracy: 0.9259 - val_loss: 0.6730 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2010 - accuracy: 0.9222 - val_loss: 0.6795 - val_accuracy: 0.7426 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2001 - accuracy: 0.9241 - val_loss: 0.6863 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.1905 - accuracy: 0.9296 - val_loss: 0.6913 - val_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2040 - accuracy: 0.9389 - val_loss: 0.6905 - val_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2004 - accuracy: 0.9259 - val_loss: 0.6875 - val_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1986 - accuracy: 0.9204 - val_loss: 0.6848 - val_accuracy: 0.7426 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2201 - accuracy: 0.9056 - val_loss: 0.6848 - val_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1905 - accuracy: 0.9259 - val_loss: 0.6863 - val_accuracy: 0.7500 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2020 - accuracy: 0.9222 - val_loss: 0.6885 - val_accuracy: 0.7500 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1913 - accuracy: 0.9315 - val_loss: 0.6890 - val_accuracy: 0.7500 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1994 - accuracy: 0.9222 - val_loss: 0.6873 - val_accuracy: 0.7500 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2138 - accuracy: 0.9074 - val_loss: 0.6860 - val_accuracy: 0.7500 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1875 - accuracy: 0.9315 - val_loss: 0.6873 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1983 - accuracy: 0.9204 - val_loss: 0.6874 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1986 - accuracy: 0.9296 - val_loss: 0.6861 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1860 - accuracy: 0.9296 - val_loss: 0.6866 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2251 - accuracy: 0.9204 - val_loss: 0.6853 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1804 - accuracy: 0.9370 - val_loss: 0.6847 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1859 - accuracy: 0.9278 - val_loss: 0.6847 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2096 - accuracy: 0.9241 - val_loss: 0.6858 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1848 - accuracy: 0.9352 - val_loss: 0.6854 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2048 - accuracy: 0.9185 - val_loss: 0.6864 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1848 - accuracy: 0.9315 - val_loss: 0.6876 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2053 - accuracy: 0.9056 - val_loss: 0.6896 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1908 - accuracy: 0.9222 - val_loss: 0.6910 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1916 - accuracy: 0.9278 - val_loss: 0.6919 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2108 - accuracy: 0.9167 - val_loss: 0.6921 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1792 - accuracy: 0.9278 - val_loss: 0.6908 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1846 - accuracy: 0.9333 - val_loss: 0.6903 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1936 - accuracy: 0.9259 - val_loss: 0.6904 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2046 - accuracy: 0.9352 - val_loss: 0.6911 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1813 - accuracy: 0.9259 - val_loss: 0.6915 - val_accuracy: 0.7574 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 101ms/step - loss: 0.6918 - accuracy: 0.5477 - val_loss: 0.6967 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6930 - accuracy: 0.5402 - val_loss: 0.6803 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6840 - accuracy: 0.5738 - val_loss: 0.6840 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6842 - accuracy: 0.5757 - val_loss: 0.6745 - val_accuracy: 0.5746 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6768 - accuracy: 0.5682 - val_loss: 0.6802 - val_accuracy: 0.5224 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6787 - accuracy: 0.5664 - val_loss: 0.6686 - val_accuracy: 0.6418 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6720 - accuracy: 0.6056 - val_loss: 0.6645 - val_accuracy: 0.6418 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6567 - accuracy: 0.6019 - val_loss: 0.6340 - val_accuracy: 0.6418 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6543 - accuracy: 0.6019 - val_loss: 0.6420 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6236 - accuracy: 0.6430 - val_loss: 0.6085 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6059 - accuracy: 0.6654 - val_loss: 0.5826 - val_accuracy: 0.7239 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6066 - accuracy: 0.6710 - val_loss: 0.5847 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5895 - accuracy: 0.6991 - val_loss: 0.5547 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5573 - accuracy: 0.7234 - val_loss: 0.5302 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5270 - accuracy: 0.7383 - val_loss: 0.5062 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4950 - accuracy: 0.7570 - val_loss: 0.4962 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5269 - accuracy: 0.7234 - val_loss: 0.5358 - val_accuracy: 0.7612 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4971 - accuracy: 0.7607 - val_loss: 0.5325 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4797 - accuracy: 0.7813 - val_loss: 0.5137 - val_accuracy: 0.7612 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4840 - accuracy: 0.7626 - val_loss: 0.5042 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4368 - accuracy: 0.8019 - val_loss: 0.5094 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4226 - accuracy: 0.8187 - val_loss: 0.4837 - val_accuracy: 0.7836 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3872 - accuracy: 0.8262 - val_loss: 0.4944 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3722 - accuracy: 0.8206 - val_loss: 0.4725 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3716 - accuracy: 0.8224 - val_loss: 0.5205 - val_accuracy: 0.7463 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3671 - accuracy: 0.8393 - val_loss: 0.5114 - val_accuracy: 0.7612 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3681 - accuracy: 0.8336 - val_loss: 0.4782 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3428 - accuracy: 0.8561 - val_loss: 0.4535 - val_accuracy: 0.8433 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3138 - accuracy: 0.8598 - val_loss: 0.4886 - val_accuracy: 0.7985 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3452 - accuracy: 0.8561 - val_loss: 0.4670 - val_accuracy: 0.7910 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3031 - accuracy: 0.8654 - val_loss: 0.4568 - val_accuracy: 0.8134 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3130 - accuracy: 0.8579 - val_loss: 0.5001 - val_accuracy: 0.7836 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3091 - accuracy: 0.8561 - val_loss: 0.4537 - val_accuracy: 0.7985 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2967 - accuracy: 0.8766 - val_loss: 0.4593 - val_accuracy: 0.8134 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2586 - accuracy: 0.8860 - val_loss: 0.4465 - val_accuracy: 0.8060 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2617 - accuracy: 0.8822 - val_loss: 0.4708 - val_accuracy: 0.7985 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2535 - accuracy: 0.8916 - val_loss: 0.4687 - val_accuracy: 0.8284 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2648 - accuracy: 0.8841 - val_loss: 0.4576 - val_accuracy: 0.8209 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2571 - accuracy: 0.8766 - val_loss: 0.4909 - val_accuracy: 0.8284 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2685 - accuracy: 0.8766 - val_loss: 0.4795 - val_accuracy: 0.7910 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2255 - accuracy: 0.9084 - val_loss: 0.4854 - val_accuracy: 0.7985 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2389 - accuracy: 0.8953 - val_loss: 0.4887 - val_accuracy: 0.7985 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2407 - accuracy: 0.9009 - val_loss: 0.4895 - val_accuracy: 0.8134 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2235 - accuracy: 0.9047 - val_loss: 0.4958 - val_accuracy: 0.8134 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2326 - accuracy: 0.8916 - val_loss: 0.4876 - val_accuracy: 0.8060 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2323 - accuracy: 0.8897 - val_loss: 0.4831 - val_accuracy: 0.7910 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2148 - accuracy: 0.9121 - val_loss: 0.4867 - val_accuracy: 0.8358 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2257 - accuracy: 0.8991 - val_loss: 0.5035 - val_accuracy: 0.8134 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1876 - accuracy: 0.9215 - val_loss: 0.4899 - val_accuracy: 0.7910 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2113 - accuracy: 0.9047 - val_loss: 0.4928 - val_accuracy: 0.7836 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2204 - accuracy: 0.8935 - val_loss: 0.4942 - val_accuracy: 0.7985 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2173 - accuracy: 0.9103 - val_loss: 0.4920 - val_accuracy: 0.7985 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2141 - accuracy: 0.9047 - val_loss: 0.4933 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2126 - accuracy: 0.9178 - val_loss: 0.4912 - val_accuracy: 0.8209 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2055 - accuracy: 0.9159 - val_loss: 0.4952 - val_accuracy: 0.8209 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2124 - accuracy: 0.9065 - val_loss: 0.4945 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1931 - accuracy: 0.9196 - val_loss: 0.4956 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2433 - accuracy: 0.8879 - val_loss: 0.4941 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1855 - accuracy: 0.9196 - val_loss: 0.4963 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2072 - accuracy: 0.9159 - val_loss: 0.4963 - val_accuracy: 0.8209 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2118 - accuracy: 0.9140 - val_loss: 0.4959 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2410 - accuracy: 0.8991 - val_loss: 0.4964 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1984 - accuracy: 0.8991 - val_loss: 0.4957 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2208 - accuracy: 0.9159 - val_loss: 0.4950 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2055 - accuracy: 0.9103 - val_loss: 0.4936 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2168 - accuracy: 0.9028 - val_loss: 0.4927 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.4927 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2115 - accuracy: 0.9065 - val_loss: 0.4907 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2187 - accuracy: 0.9196 - val_loss: 0.4909 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2063 - accuracy: 0.9065 - val_loss: 0.4922 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2196 - accuracy: 0.9103 - val_loss: 0.4918 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1975 - accuracy: 0.9178 - val_loss: 0.4924 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2156 - accuracy: 0.9159 - val_loss: 0.4934 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1739 - accuracy: 0.9215 - val_loss: 0.4966 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2062 - accuracy: 0.9103 - val_loss: 0.4970 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2049 - accuracy: 0.9159 - val_loss: 0.4959 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2075 - accuracy: 0.9140 - val_loss: 0.4958 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2196 - accuracy: 0.9103 - val_loss: 0.4958 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2033 - accuracy: 0.9196 - val_loss: 0.4969 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2360 - accuracy: 0.8916 - val_loss: 0.4962 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2182 - accuracy: 0.9028 - val_loss: 0.4956 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2213 - accuracy: 0.9047 - val_loss: 0.4932 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2249 - accuracy: 0.9028 - val_loss: 0.4925 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1963 - accuracy: 0.9159 - val_loss: 0.4915 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.1890 - accuracy: 0.9346 - val_loss: 0.4908 - val_accuracy: 0.8060 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 100ms/step - loss: 0.7135 - accuracy: 0.5524 - val_loss: 0.6977 - val_accuracy: 0.3864 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6974 - accuracy: 0.4762 - val_loss: 0.6966 - val_accuracy: 0.4848 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6917 - accuracy: 0.5600 - val_loss: 0.7014 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6919 - accuracy: 0.5371 - val_loss: 0.6640 - val_accuracy: 0.6364 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6977 - accuracy: 0.5314 - val_loss: 0.6961 - val_accuracy: 0.4318 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6861 - accuracy: 0.5467 - val_loss: 0.6806 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6722 - accuracy: 0.5771 - val_loss: 0.7142 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6719 - accuracy: 0.5867 - val_loss: 0.6750 - val_accuracy: 0.5379 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6625 - accuracy: 0.5714 - val_loss: 0.6902 - val_accuracy: 0.4394 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6620 - accuracy: 0.5771 - val_loss: 0.6629 - val_accuracy: 0.5530 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6420 - accuracy: 0.6171 - val_loss: 0.6721 - val_accuracy: 0.5379 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6472 - accuracy: 0.6095 - val_loss: 0.6670 - val_accuracy: 0.5758 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6367 - accuracy: 0.6305 - val_loss: 0.6689 - val_accuracy: 0.5530 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6198 - accuracy: 0.6152 - val_loss: 0.6536 - val_accuracy: 0.5682 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6185 - accuracy: 0.6419 - val_loss: 0.6578 - val_accuracy: 0.5682 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6196 - accuracy: 0.6343 - val_loss: 0.6614 - val_accuracy: 0.5682 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6231 - accuracy: 0.6457 - val_loss: 0.6461 - val_accuracy: 0.6439 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6128 - accuracy: 0.6476 - val_loss: 0.6520 - val_accuracy: 0.5530 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5973 - accuracy: 0.6781 - val_loss: 0.6384 - val_accuracy: 0.5909 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5753 - accuracy: 0.6933 - val_loss: 0.6542 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5857 - accuracy: 0.6724 - val_loss: 0.6211 - val_accuracy: 0.6288 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5478 - accuracy: 0.7257 - val_loss: 0.6691 - val_accuracy: 0.6136 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5826 - accuracy: 0.6648 - val_loss: 0.6308 - val_accuracy: 0.6591 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5500 - accuracy: 0.7105 - val_loss: 0.6326 - val_accuracy: 0.6136 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5335 - accuracy: 0.7257 - val_loss: 0.5919 - val_accuracy: 0.6818 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5394 - accuracy: 0.7105 - val_loss: 0.5923 - val_accuracy: 0.6970 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5100 - accuracy: 0.7467 - val_loss: 0.6113 - val_accuracy: 0.6894 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5017 - accuracy: 0.7790 - val_loss: 0.6252 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5127 - accuracy: 0.7486 - val_loss: 0.5760 - val_accuracy: 0.7197 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4744 - accuracy: 0.8057 - val_loss: 0.5580 - val_accuracy: 0.7576 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4896 - accuracy: 0.7829 - val_loss: 0.5809 - val_accuracy: 0.7121 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4787 - accuracy: 0.7771 - val_loss: 0.5510 - val_accuracy: 0.7424 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4607 - accuracy: 0.7848 - val_loss: 0.5408 - val_accuracy: 0.7576 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4505 - accuracy: 0.7810 - val_loss: 0.5574 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4432 - accuracy: 0.8114 - val_loss: 0.5609 - val_accuracy: 0.7424 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4506 - accuracy: 0.7981 - val_loss: 0.5662 - val_accuracy: 0.7652 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4574 - accuracy: 0.8057 - val_loss: 0.5372 - val_accuracy: 0.7652 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3982 - accuracy: 0.8400 - val_loss: 0.5433 - val_accuracy: 0.7576 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4131 - accuracy: 0.8076 - val_loss: 0.5582 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4130 - accuracy: 0.8286 - val_loss: 0.5511 - val_accuracy: 0.7424 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3742 - accuracy: 0.8457 - val_loss: 0.5080 - val_accuracy: 0.7955 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3692 - accuracy: 0.8171 - val_loss: 0.5616 - val_accuracy: 0.7803 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3738 - accuracy: 0.8419 - val_loss: 0.5598 - val_accuracy: 0.7879 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3589 - accuracy: 0.8419 - val_loss: 0.5530 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3716 - accuracy: 0.8267 - val_loss: 0.5262 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.3385 - accuracy: 0.8590 - val_loss: 0.5204 - val_accuracy: 0.8106 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3413 - accuracy: 0.8438 - val_loss: 0.5181 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.3246 - accuracy: 0.8705 - val_loss: 0.5276 - val_accuracy: 0.7727 - lr: 2.5000e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.3382 - accuracy: 0.8476 - val_loss: 0.5464 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2929 - accuracy: 0.8895 - val_loss: 0.5494 - val_accuracy: 0.7652 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3147 - accuracy: 0.8686 - val_loss: 0.5220 - val_accuracy: 0.7955 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3108 - accuracy: 0.8648 - val_loss: 0.5020 - val_accuracy: 0.7955 - lr: 1.2500e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2914 - accuracy: 0.8838 - val_loss: 0.5175 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2925 - accuracy: 0.8743 - val_loss: 0.4970 - val_accuracy: 0.7727 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2710 - accuracy: 0.8857 - val_loss: 0.5007 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2884 - accuracy: 0.8819 - val_loss: 0.5379 - val_accuracy: 0.7727 - lr: 1.2500e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3228 - accuracy: 0.8514 - val_loss: 0.5273 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2916 - accuracy: 0.8876 - val_loss: 0.5440 - val_accuracy: 0.7803 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3119 - accuracy: 0.8667 - val_loss: 0.5411 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2738 - accuracy: 0.8876 - val_loss: 0.5109 - val_accuracy: 0.7879 - lr: 6.2500e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2655 - accuracy: 0.9086 - val_loss: 0.5092 - val_accuracy: 0.7879 - lr: 6.2500e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2719 - accuracy: 0.8876 - val_loss: 0.5107 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2775 - accuracy: 0.8629 - val_loss: 0.5148 - val_accuracy: 0.7955 - lr: 6.2500e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2507 - accuracy: 0.9105 - val_loss: 0.5191 - val_accuracy: 0.7955 - lr: 6.2500e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2730 - accuracy: 0.8724 - val_loss: 0.5195 - val_accuracy: 0.7955 - lr: 3.1250e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2593 - accuracy: 0.8990 - val_loss: 0.5235 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2623 - accuracy: 0.8971 - val_loss: 0.5164 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2774 - accuracy: 0.8838 - val_loss: 0.5216 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2629 - accuracy: 0.8914 - val_loss: 0.5206 - val_accuracy: 0.7955 - lr: 3.1250e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2607 - accuracy: 0.8838 - val_loss: 0.5218 - val_accuracy: 0.7955 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2496 - accuracy: 0.9029 - val_loss: 0.5247 - val_accuracy: 0.7955 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2675 - accuracy: 0.8933 - val_loss: 0.5256 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2863 - accuracy: 0.8743 - val_loss: 0.5285 - val_accuracy: 0.7955 - lr: 1.5625e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2557 - accuracy: 0.8876 - val_loss: 0.5291 - val_accuracy: 0.7955 - lr: 1.5625e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2721 - accuracy: 0.8743 - val_loss: 0.5289 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2667 - accuracy: 0.8800 - val_loss: 0.5280 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2805 - accuracy: 0.8857 - val_loss: 0.5256 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2551 - accuracy: 0.8838 - val_loss: 0.5244 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2778 - accuracy: 0.8952 - val_loss: 0.5245 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2590 - accuracy: 0.8971 - val_loss: 0.5265 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2657 - accuracy: 0.8781 - val_loss: 0.5274 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2564 - accuracy: 0.8933 - val_loss: 0.5278 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2581 - accuracy: 0.8686 - val_loss: 0.5297 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2734 - accuracy: 0.8933 - val_loss: 0.5279 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.2708 - accuracy: 0.8895 - val_loss: 0.5272 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2416 - accuracy: 0.9067 - val_loss: 0.5291 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2769 - accuracy: 0.8895 - val_loss: 0.5307 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2684 - accuracy: 0.8990 - val_loss: 0.5302 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2424 - accuracy: 0.9162 - val_loss: 0.5301 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2538 - accuracy: 0.8914 - val_loss: 0.5319 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2558 - accuracy: 0.8933 - val_loss: 0.5333 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2673 - accuracy: 0.8819 - val_loss: 0.5345 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2942 - accuracy: 0.8686 - val_loss: 0.5361 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2656 - accuracy: 0.8895 - val_loss: 0.5332 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2377 - accuracy: 0.9048 - val_loss: 0.5324 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2824 - accuracy: 0.8800 - val_loss: 0.5322 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2595 - accuracy: 0.8781 - val_loss: 0.5334 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2819 - accuracy: 0.8838 - val_loss: 0.5338 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2718 - accuracy: 0.8800 - val_loss: 0.5347 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2544 - accuracy: 0.9029 - val_loss: 0.5327 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_model((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d8cf779-6de1-407a-83ea-0563edc8feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.7515\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.7619\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.8242\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be8a97e9-0063-4ca3-89ce-af63fc8ebc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}\n",
    "\n",
    "def create_cnn_lstm_2(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eec0bba8-9b73-4029-bc91-e946fe31462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 102ms/step - loss: 0.6889 - accuracy: 0.5389 - val_loss: 0.6826 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6891 - accuracy: 0.5389 - val_loss: 0.6796 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6866 - accuracy: 0.5463 - val_loss: 0.6766 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6850 - accuracy: 0.5444 - val_loss: 0.6740 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6881 - accuracy: 0.5444 - val_loss: 0.6748 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6816 - accuracy: 0.5463 - val_loss: 0.6739 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6833 - accuracy: 0.5444 - val_loss: 0.6740 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6823 - accuracy: 0.5463 - val_loss: 0.6723 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6884 - accuracy: 0.5481 - val_loss: 0.6737 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6820 - accuracy: 0.5426 - val_loss: 0.6729 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6837 - accuracy: 0.5593 - val_loss: 0.6709 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6826 - accuracy: 0.5500 - val_loss: 0.6710 - val_accuracy: 0.6029 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6837 - accuracy: 0.5648 - val_loss: 0.6704 - val_accuracy: 0.6103 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6794 - accuracy: 0.5741 - val_loss: 0.6696 - val_accuracy: 0.6176 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6845 - accuracy: 0.5444 - val_loss: 0.6712 - val_accuracy: 0.6103 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6835 - accuracy: 0.5519 - val_loss: 0.6692 - val_accuracy: 0.6176 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6804 - accuracy: 0.5611 - val_loss: 0.6702 - val_accuracy: 0.6103 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6759 - accuracy: 0.5537 - val_loss: 0.6713 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6816 - accuracy: 0.5685 - val_loss: 0.6751 - val_accuracy: 0.6324 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6792 - accuracy: 0.5630 - val_loss: 0.6711 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6810 - accuracy: 0.5574 - val_loss: 0.6685 - val_accuracy: 0.6324 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6808 - accuracy: 0.5648 - val_loss: 0.6699 - val_accuracy: 0.6324 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6789 - accuracy: 0.5611 - val_loss: 0.6699 - val_accuracy: 0.6324 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6779 - accuracy: 0.5667 - val_loss: 0.6688 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6766 - accuracy: 0.5611 - val_loss: 0.6691 - val_accuracy: 0.6324 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6806 - accuracy: 0.5537 - val_loss: 0.6717 - val_accuracy: 0.6397 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6781 - accuracy: 0.5611 - val_loss: 0.6685 - val_accuracy: 0.6397 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6768 - accuracy: 0.5722 - val_loss: 0.6678 - val_accuracy: 0.6324 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6736 - accuracy: 0.5815 - val_loss: 0.6662 - val_accuracy: 0.6176 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6771 - accuracy: 0.5852 - val_loss: 0.6673 - val_accuracy: 0.6324 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6750 - accuracy: 0.5852 - val_loss: 0.6668 - val_accuracy: 0.6324 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6786 - accuracy: 0.5500 - val_loss: 0.6666 - val_accuracy: 0.6250 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6767 - accuracy: 0.5778 - val_loss: 0.6672 - val_accuracy: 0.6324 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6719 - accuracy: 0.5833 - val_loss: 0.6664 - val_accuracy: 0.6250 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6756 - accuracy: 0.5722 - val_loss: 0.6672 - val_accuracy: 0.6471 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6730 - accuracy: 0.5815 - val_loss: 0.6668 - val_accuracy: 0.6471 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6733 - accuracy: 0.5574 - val_loss: 0.6666 - val_accuracy: 0.6397 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6760 - accuracy: 0.5963 - val_loss: 0.6667 - val_accuracy: 0.6471 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6777 - accuracy: 0.5907 - val_loss: 0.6663 - val_accuracy: 0.6397 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6779 - accuracy: 0.5796 - val_loss: 0.6664 - val_accuracy: 0.6471 - lr: 0.0012\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6778 - accuracy: 0.5667 - val_loss: 0.6664 - val_accuracy: 0.6471 - lr: 0.0012\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6755 - accuracy: 0.5685 - val_loss: 0.6660 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6724 - accuracy: 0.5574 - val_loss: 0.6658 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6755 - accuracy: 0.5648 - val_loss: 0.6658 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6781 - accuracy: 0.5944 - val_loss: 0.6660 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6745 - accuracy: 0.5852 - val_loss: 0.6660 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6729 - accuracy: 0.5611 - val_loss: 0.6659 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6745 - accuracy: 0.5741 - val_loss: 0.6657 - val_accuracy: 0.6397 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6744 - accuracy: 0.5667 - val_loss: 0.6658 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6773 - accuracy: 0.5537 - val_loss: 0.6659 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6734 - accuracy: 0.5722 - val_loss: 0.6657 - val_accuracy: 0.6397 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6719 - accuracy: 0.5759 - val_loss: 0.6656 - val_accuracy: 0.6397 - lr: 6.2500e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6727 - accuracy: 0.5944 - val_loss: 0.6657 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6731 - accuracy: 0.5815 - val_loss: 0.6656 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6743 - accuracy: 0.5852 - val_loss: 0.6656 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6723 - accuracy: 0.5963 - val_loss: 0.6656 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6717 - accuracy: 0.5778 - val_loss: 0.6655 - val_accuracy: 0.6324 - lr: 6.2500e-04\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6710 - accuracy: 0.6037 - val_loss: 0.6655 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6731 - accuracy: 0.5870 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6741 - accuracy: 0.5870 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6695 - accuracy: 0.6000 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6739 - accuracy: 0.5722 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6715 - accuracy: 0.5889 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6712 - accuracy: 0.5944 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.1250e-04\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6733 - accuracy: 0.5704 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.5625e-04\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6721 - accuracy: 0.5685 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.5625e-04\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6769 - accuracy: 0.5759 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6778 - accuracy: 0.5704 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.5625e-04\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6719 - accuracy: 0.5926 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.5625e-04\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6736 - accuracy: 0.5815 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 7.8125e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6750 - accuracy: 0.5889 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 7.8125e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6749 - accuracy: 0.5926 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 7.8125e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6759 - accuracy: 0.5778 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 7.8125e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6694 - accuracy: 0.5907 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 7.8125e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6756 - accuracy: 0.5926 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.9062e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6738 - accuracy: 0.5907 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.9062e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6729 - accuracy: 0.5759 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.9062e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6730 - accuracy: 0.5685 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 3.9062e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6717 - accuracy: 0.5963 - val_loss: 0.6655 - val_accuracy: 0.6324 - lr: 3.9062e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6738 - accuracy: 0.5685 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.9531e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6718 - accuracy: 0.5963 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.9531e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6745 - accuracy: 0.5741 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.9531e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6715 - accuracy: 0.5630 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.9531e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6738 - accuracy: 0.5944 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.9531e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6750 - accuracy: 0.5759 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6732 - accuracy: 0.5722 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6741 - accuracy: 0.5796 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6762 - accuracy: 0.5667 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6740 - accuracy: 0.5667 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6703 - accuracy: 0.5833 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6764 - accuracy: 0.5593 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6738 - accuracy: 0.5815 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6758 - accuracy: 0.5741 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.6699 - accuracy: 0.5815 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 4s 217ms/step - loss: 0.6741 - accuracy: 0.5926 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6732 - accuracy: 0.5648 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6741 - accuracy: 0.5667 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6698 - accuracy: 0.5741 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6754 - accuracy: 0.5778 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6740 - accuracy: 0.5667 - val_loss: 0.6654 - val_accuracy: 0.6324 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 14ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 8s 98ms/step - loss: 0.6921 - accuracy: 0.5103 - val_loss: 0.6859 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6876 - accuracy: 0.5682 - val_loss: 0.6829 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6888 - accuracy: 0.5570 - val_loss: 0.6819 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6834 - accuracy: 0.5589 - val_loss: 0.6812 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6890 - accuracy: 0.5514 - val_loss: 0.6809 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6849 - accuracy: 0.5645 - val_loss: 0.6812 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6832 - accuracy: 0.5533 - val_loss: 0.6817 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6881 - accuracy: 0.5570 - val_loss: 0.6809 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6827 - accuracy: 0.5626 - val_loss: 0.6805 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6813 - accuracy: 0.5570 - val_loss: 0.6803 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6814 - accuracy: 0.5607 - val_loss: 0.6796 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6812 - accuracy: 0.5645 - val_loss: 0.6786 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6868 - accuracy: 0.5607 - val_loss: 0.6786 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6818 - accuracy: 0.5514 - val_loss: 0.6783 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6824 - accuracy: 0.5477 - val_loss: 0.6777 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6810 - accuracy: 0.5682 - val_loss: 0.6781 - val_accuracy: 0.5522 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6815 - accuracy: 0.5551 - val_loss: 0.6789 - val_accuracy: 0.5896 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6815 - accuracy: 0.5720 - val_loss: 0.6766 - val_accuracy: 0.5448 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6816 - accuracy: 0.5589 - val_loss: 0.6761 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6811 - accuracy: 0.5533 - val_loss: 0.6752 - val_accuracy: 0.5522 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6795 - accuracy: 0.5570 - val_loss: 0.6748 - val_accuracy: 0.5821 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6758 - accuracy: 0.5832 - val_loss: 0.6736 - val_accuracy: 0.5522 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6805 - accuracy: 0.5720 - val_loss: 0.6731 - val_accuracy: 0.5522 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6756 - accuracy: 0.5813 - val_loss: 0.6723 - val_accuracy: 0.5746 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6757 - accuracy: 0.5645 - val_loss: 0.6718 - val_accuracy: 0.5746 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6736 - accuracy: 0.5645 - val_loss: 0.6724 - val_accuracy: 0.6418 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6783 - accuracy: 0.5570 - val_loss: 0.6701 - val_accuracy: 0.5746 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6764 - accuracy: 0.5813 - val_loss: 0.6700 - val_accuracy: 0.6045 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6736 - accuracy: 0.5364 - val_loss: 0.6697 - val_accuracy: 0.6418 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6742 - accuracy: 0.5664 - val_loss: 0.6685 - val_accuracy: 0.5896 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6773 - accuracy: 0.5813 - val_loss: 0.6680 - val_accuracy: 0.5821 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6724 - accuracy: 0.5607 - val_loss: 0.6669 - val_accuracy: 0.5896 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6720 - accuracy: 0.5626 - val_loss: 0.6664 - val_accuracy: 0.5896 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6730 - accuracy: 0.5757 - val_loss: 0.6658 - val_accuracy: 0.6269 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.6695 - accuracy: 0.5925 - val_loss: 0.6659 - val_accuracy: 0.6418 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 5s 337ms/step - loss: 0.6688 - accuracy: 0.5682 - val_loss: 0.6644 - val_accuracy: 0.6269 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 2s 81ms/step - loss: 0.6694 - accuracy: 0.5682 - val_loss: 0.6635 - val_accuracy: 0.5970 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6741 - accuracy: 0.5757 - val_loss: 0.6646 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6679 - accuracy: 0.5944 - val_loss: 0.6630 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6688 - accuracy: 0.5776 - val_loss: 0.6618 - val_accuracy: 0.6194 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6734 - accuracy: 0.5738 - val_loss: 0.6615 - val_accuracy: 0.6045 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6699 - accuracy: 0.5402 - val_loss: 0.6607 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6704 - accuracy: 0.5832 - val_loss: 0.6598 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6675 - accuracy: 0.5701 - val_loss: 0.6593 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6635 - accuracy: 0.6075 - val_loss: 0.6586 - val_accuracy: 0.6343 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6589 - accuracy: 0.5907 - val_loss: 0.6576 - val_accuracy: 0.6418 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6605 - accuracy: 0.5832 - val_loss: 0.6572 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6650 - accuracy: 0.5701 - val_loss: 0.6575 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6620 - accuracy: 0.5813 - val_loss: 0.6571 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6612 - accuracy: 0.5738 - val_loss: 0.6568 - val_accuracy: 0.6493 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6671 - accuracy: 0.5869 - val_loss: 0.6555 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6615 - accuracy: 0.5850 - val_loss: 0.6547 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6592 - accuracy: 0.5869 - val_loss: 0.6529 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6628 - accuracy: 0.5794 - val_loss: 0.6525 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6619 - accuracy: 0.5888 - val_loss: 0.6521 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6561 - accuracy: 0.5907 - val_loss: 0.6510 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.6578 - accuracy: 0.5794 - val_loss: 0.6506 - val_accuracy: 0.6493 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 4s 219ms/step - loss: 0.6576 - accuracy: 0.6112 - val_loss: 0.6497 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6555 - accuracy: 0.5944 - val_loss: 0.6487 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6528 - accuracy: 0.5944 - val_loss: 0.6501 - val_accuracy: 0.6493 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6530 - accuracy: 0.5925 - val_loss: 0.6496 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6495 - accuracy: 0.6168 - val_loss: 0.6465 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6565 - accuracy: 0.5850 - val_loss: 0.6468 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6512 - accuracy: 0.6150 - val_loss: 0.6458 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6484 - accuracy: 0.6243 - val_loss: 0.6435 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6506 - accuracy: 0.6019 - val_loss: 0.6438 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6519 - accuracy: 0.6075 - val_loss: 0.6442 - val_accuracy: 0.6418 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6492 - accuracy: 0.5925 - val_loss: 0.6428 - val_accuracy: 0.6343 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6473 - accuracy: 0.6019 - val_loss: 0.6405 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6501 - accuracy: 0.6243 - val_loss: 0.6413 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6395 - accuracy: 0.6318 - val_loss: 0.6380 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6528 - accuracy: 0.6150 - val_loss: 0.6375 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6409 - accuracy: 0.6262 - val_loss: 0.6374 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6555 - accuracy: 0.6093 - val_loss: 0.6364 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6431 - accuracy: 0.6075 - val_loss: 0.6361 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6454 - accuracy: 0.6112 - val_loss: 0.6357 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6439 - accuracy: 0.6000 - val_loss: 0.6333 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6291 - accuracy: 0.6430 - val_loss: 0.6303 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.6319 - accuracy: 0.6168 - val_loss: 0.6297 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.6347 - accuracy: 0.6075 - val_loss: 0.6282 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.6268 - accuracy: 0.6243 - val_loss: 0.6261 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6357 - accuracy: 0.6187 - val_loss: 0.6251 - val_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6274 - accuracy: 0.6150 - val_loss: 0.6252 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6286 - accuracy: 0.6280 - val_loss: 0.6239 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6273 - accuracy: 0.6393 - val_loss: 0.6218 - val_accuracy: 0.6866 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6352 - accuracy: 0.6056 - val_loss: 0.6214 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6374 - accuracy: 0.6150 - val_loss: 0.6211 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6307 - accuracy: 0.6243 - val_loss: 0.6184 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6332 - accuracy: 0.6262 - val_loss: 0.6179 - val_accuracy: 0.6642 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6275 - accuracy: 0.6318 - val_loss: 0.6154 - val_accuracy: 0.7015 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6267 - accuracy: 0.6206 - val_loss: 0.6152 - val_accuracy: 0.7015 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6289 - accuracy: 0.6374 - val_loss: 0.6150 - val_accuracy: 0.6791 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6248 - accuracy: 0.6579 - val_loss: 0.6132 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6309 - accuracy: 0.6056 - val_loss: 0.6122 - val_accuracy: 0.6866 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6238 - accuracy: 0.6318 - val_loss: 0.6120 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6276 - accuracy: 0.6505 - val_loss: 0.6151 - val_accuracy: 0.6940 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6087 - accuracy: 0.6673 - val_loss: 0.6083 - val_accuracy: 0.7015 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6157 - accuracy: 0.6206 - val_loss: 0.6068 - val_accuracy: 0.7015 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6250 - accuracy: 0.6486 - val_loss: 0.6079 - val_accuracy: 0.6716 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6120 - accuracy: 0.6617 - val_loss: 0.6068 - val_accuracy: 0.6940 - lr: 0.0100\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 97ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6902 - val_accuracy: 0.6288 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6920 - accuracy: 0.5143 - val_loss: 0.6872 - val_accuracy: 0.6136 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6838 - val_accuracy: 0.6136 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6943 - accuracy: 0.5105 - val_loss: 0.6850 - val_accuracy: 0.6136 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6915 - accuracy: 0.5352 - val_loss: 0.6849 - val_accuracy: 0.6591 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6926 - accuracy: 0.4895 - val_loss: 0.6855 - val_accuracy: 0.6894 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6912 - accuracy: 0.5333 - val_loss: 0.6866 - val_accuracy: 0.6212 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6910 - accuracy: 0.5390 - val_loss: 0.6862 - val_accuracy: 0.5909 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6899 - accuracy: 0.5638 - val_loss: 0.6848 - val_accuracy: 0.6061 - lr: 0.0050\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6903 - accuracy: 0.5467 - val_loss: 0.6847 - val_accuracy: 0.6136 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6900 - accuracy: 0.5638 - val_loss: 0.6856 - val_accuracy: 0.5909 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6896 - accuracy: 0.5676 - val_loss: 0.6843 - val_accuracy: 0.6061 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6922 - accuracy: 0.5105 - val_loss: 0.6841 - val_accuracy: 0.5985 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6893 - accuracy: 0.5657 - val_loss: 0.6837 - val_accuracy: 0.5985 - lr: 0.0025\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.6876 - accuracy: 0.5581 - val_loss: 0.6833 - val_accuracy: 0.5985 - lr: 0.0025\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6906 - accuracy: 0.5581 - val_loss: 0.6827 - val_accuracy: 0.6288 - lr: 0.0025\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6911 - accuracy: 0.5314 - val_loss: 0.6822 - val_accuracy: 0.6515 - lr: 0.0025\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6905 - accuracy: 0.5352 - val_loss: 0.6818 - val_accuracy: 0.6515 - lr: 0.0025\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6910 - accuracy: 0.5181 - val_loss: 0.6817 - val_accuracy: 0.6515 - lr: 0.0025\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6904 - accuracy: 0.5410 - val_loss: 0.6819 - val_accuracy: 0.6364 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6908 - accuracy: 0.5181 - val_loss: 0.6818 - val_accuracy: 0.6439 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6871 - accuracy: 0.5657 - val_loss: 0.6814 - val_accuracy: 0.6515 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6914 - accuracy: 0.5314 - val_loss: 0.6816 - val_accuracy: 0.6364 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6887 - accuracy: 0.5657 - val_loss: 0.6812 - val_accuracy: 0.6288 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6807 - val_accuracy: 0.6364 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6913 - accuracy: 0.5162 - val_loss: 0.6817 - val_accuracy: 0.6212 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6895 - accuracy: 0.5581 - val_loss: 0.6816 - val_accuracy: 0.6061 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6894 - accuracy: 0.5429 - val_loss: 0.6813 - val_accuracy: 0.6212 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6888 - accuracy: 0.5429 - val_loss: 0.6810 - val_accuracy: 0.6212 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6887 - accuracy: 0.5486 - val_loss: 0.6811 - val_accuracy: 0.6136 - lr: 0.0025\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6881 - accuracy: 0.5619 - val_loss: 0.6808 - val_accuracy: 0.6136 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6885 - accuracy: 0.5619 - val_loss: 0.6810 - val_accuracy: 0.6061 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6885 - accuracy: 0.5657 - val_loss: 0.6808 - val_accuracy: 0.6136 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6891 - accuracy: 0.5714 - val_loss: 0.6807 - val_accuracy: 0.6136 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6890 - accuracy: 0.5562 - val_loss: 0.6805 - val_accuracy: 0.6136 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6881 - accuracy: 0.5505 - val_loss: 0.6810 - val_accuracy: 0.6061 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6891 - accuracy: 0.5543 - val_loss: 0.6806 - val_accuracy: 0.6061 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6908 - accuracy: 0.5505 - val_loss: 0.6805 - val_accuracy: 0.6136 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6891 - accuracy: 0.5733 - val_loss: 0.6805 - val_accuracy: 0.6061 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6887 - accuracy: 0.5676 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 0.0012\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6875 - accuracy: 0.5771 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6891 - accuracy: 0.5600 - val_loss: 0.6804 - val_accuracy: 0.6136 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6870 - accuracy: 0.5714 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6893 - accuracy: 0.5352 - val_loss: 0.6804 - val_accuracy: 0.6136 - lr: 6.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6884 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6136 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6881 - accuracy: 0.5467 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6890 - accuracy: 0.5410 - val_loss: 0.6803 - val_accuracy: 0.6136 - lr: 3.1250e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6883 - accuracy: 0.5429 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.1250e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6891 - accuracy: 0.5238 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.1250e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6880 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.1250e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 3.1250e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6877 - accuracy: 0.5410 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 1.5625e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6862 - accuracy: 0.5771 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 1.5625e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6887 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.5625e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6885 - accuracy: 0.5581 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.5625e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6865 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.5625e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6880 - accuracy: 0.5905 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 7.8125e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6869 - accuracy: 0.5790 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 7.8125e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6884 - accuracy: 0.5448 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 7.8125e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6899 - accuracy: 0.5352 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 7.8125e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6864 - accuracy: 0.5581 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 7.8125e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6870 - accuracy: 0.5429 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.9062e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6888 - accuracy: 0.5410 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.9062e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6899 - accuracy: 0.5448 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 3.9062e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6896 - accuracy: 0.5600 - val_loss: 0.6804 - val_accuracy: 0.6061 - lr: 3.9062e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6893 - accuracy: 0.5448 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 3.9062e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6893 - accuracy: 0.5390 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.9531e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6896 - accuracy: 0.5429 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.9531e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6880 - accuracy: 0.5543 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.9531e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6876 - accuracy: 0.5524 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.9531e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6886 - accuracy: 0.5676 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.9531e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6869 - accuracy: 0.5429 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6876 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6866 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6883 - accuracy: 0.5543 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6894 - accuracy: 0.5505 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6870 - accuracy: 0.5581 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6914 - accuracy: 0.5276 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6883 - accuracy: 0.5657 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6895 - accuracy: 0.5257 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6879 - accuracy: 0.5886 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6882 - accuracy: 0.5448 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6864 - accuracy: 0.5867 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6873 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6903 - accuracy: 0.5543 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6885 - accuracy: 0.5333 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6895 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6878 - accuracy: 0.5448 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6885 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6886 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6885 - accuracy: 0.5371 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6897 - accuracy: 0.5581 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6860 - accuracy: 0.5714 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6879 - accuracy: 0.5505 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6881 - accuracy: 0.5619 - val_loss: 0.6803 - val_accuracy: 0.6061 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_2((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35435642-0820-4f4d-8311-3640ee495ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.6036\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.6250\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.6303\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ac45bb7-5aea-45d8-960b-1d6aedc68921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}\n",
    "\n",
    "def create_cnn_lstm_3(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8238c551-9e28-4cd6-bf28-1b492ac479bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 98ms/step - loss: 0.7026 - accuracy: 0.5426 - val_loss: 0.6650 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.7020 - accuracy: 0.5241 - val_loss: 0.6691 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6803 - accuracy: 0.5796 - val_loss: 0.6881 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6683 - accuracy: 0.5963 - val_loss: 0.6376 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6666 - accuracy: 0.6185 - val_loss: 0.7069 - val_accuracy: 0.5368 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6545 - accuracy: 0.6278 - val_loss: 0.6514 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6444 - accuracy: 0.6389 - val_loss: 0.6930 - val_accuracy: 0.5956 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6306 - accuracy: 0.6500 - val_loss: 0.6396 - val_accuracy: 0.6618 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6146 - accuracy: 0.6796 - val_loss: 0.6560 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5994 - accuracy: 0.6852 - val_loss: 0.6370 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5952 - accuracy: 0.6889 - val_loss: 0.6433 - val_accuracy: 0.6324 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5727 - accuracy: 0.7019 - val_loss: 0.6432 - val_accuracy: 0.6324 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5558 - accuracy: 0.7074 - val_loss: 0.6238 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5548 - accuracy: 0.7074 - val_loss: 0.6342 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5363 - accuracy: 0.7370 - val_loss: 0.6411 - val_accuracy: 0.6397 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5406 - accuracy: 0.7463 - val_loss: 0.6429 - val_accuracy: 0.6471 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5384 - accuracy: 0.7444 - val_loss: 0.6244 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5109 - accuracy: 0.7537 - val_loss: 0.6358 - val_accuracy: 0.6544 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4991 - accuracy: 0.7537 - val_loss: 0.6222 - val_accuracy: 0.6691 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4905 - accuracy: 0.7537 - val_loss: 0.6278 - val_accuracy: 0.6618 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4811 - accuracy: 0.7685 - val_loss: 0.6254 - val_accuracy: 0.6838 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4668 - accuracy: 0.7704 - val_loss: 0.6259 - val_accuracy: 0.6618 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4563 - accuracy: 0.7796 - val_loss: 0.6223 - val_accuracy: 0.6544 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4605 - accuracy: 0.8000 - val_loss: 0.6356 - val_accuracy: 0.6765 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4726 - accuracy: 0.7667 - val_loss: 0.6275 - val_accuracy: 0.6765 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4430 - accuracy: 0.8111 - val_loss: 0.6288 - val_accuracy: 0.6691 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4183 - accuracy: 0.8056 - val_loss: 0.6316 - val_accuracy: 0.6765 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4370 - accuracy: 0.8056 - val_loss: 0.6276 - val_accuracy: 0.6691 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4359 - accuracy: 0.8019 - val_loss: 0.6230 - val_accuracy: 0.7206 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4312 - accuracy: 0.8111 - val_loss: 0.6246 - val_accuracy: 0.6838 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4204 - accuracy: 0.8259 - val_loss: 0.6249 - val_accuracy: 0.6838 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4209 - accuracy: 0.8204 - val_loss: 0.6229 - val_accuracy: 0.6765 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4182 - accuracy: 0.8222 - val_loss: 0.6226 - val_accuracy: 0.6838 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4309 - accuracy: 0.8056 - val_loss: 0.6232 - val_accuracy: 0.6912 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4282 - accuracy: 0.8000 - val_loss: 0.6234 - val_accuracy: 0.6912 - lr: 3.1250e-05\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4241 - accuracy: 0.8259 - val_loss: 0.6236 - val_accuracy: 0.6838 - lr: 3.1250e-05\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4249 - accuracy: 0.8148 - val_loss: 0.6230 - val_accuracy: 0.6765 - lr: 3.1250e-05\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4205 - accuracy: 0.8019 - val_loss: 0.6228 - val_accuracy: 0.6838 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4147 - accuracy: 0.8111 - val_loss: 0.6247 - val_accuracy: 0.6838 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4284 - accuracy: 0.8019 - val_loss: 0.6248 - val_accuracy: 0.6765 - lr: 1.5625e-05\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4118 - accuracy: 0.8241 - val_loss: 0.6244 - val_accuracy: 0.6765 - lr: 1.5625e-05\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4059 - accuracy: 0.8148 - val_loss: 0.6250 - val_accuracy: 0.6765 - lr: 1.5625e-05\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4304 - accuracy: 0.7981 - val_loss: 0.6246 - val_accuracy: 0.6765 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4374 - accuracy: 0.8093 - val_loss: 0.6246 - val_accuracy: 0.6765 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4214 - accuracy: 0.8093 - val_loss: 0.6240 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4139 - accuracy: 0.8296 - val_loss: 0.6250 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4006 - accuracy: 0.8167 - val_loss: 0.6251 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4183 - accuracy: 0.8093 - val_loss: 0.6254 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4289 - accuracy: 0.7944 - val_loss: 0.6260 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4111 - accuracy: 0.8389 - val_loss: 0.6261 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4414 - accuracy: 0.7963 - val_loss: 0.6252 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4054 - accuracy: 0.8204 - val_loss: 0.6255 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4197 - accuracy: 0.8222 - val_loss: 0.6261 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4143 - accuracy: 0.8148 - val_loss: 0.6258 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4398 - accuracy: 0.8037 - val_loss: 0.6262 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4141 - accuracy: 0.8111 - val_loss: 0.6263 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4062 - accuracy: 0.8259 - val_loss: 0.6269 - val_accuracy: 0.6765 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4172 - accuracy: 0.8204 - val_loss: 0.6261 - val_accuracy: 0.6765 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4062 - accuracy: 0.8167 - val_loss: 0.6258 - val_accuracy: 0.6765 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4201 - accuracy: 0.8074 - val_loss: 0.6251 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4088 - accuracy: 0.8241 - val_loss: 0.6254 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4017 - accuracy: 0.8259 - val_loss: 0.6253 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4137 - accuracy: 0.8222 - val_loss: 0.6254 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3950 - accuracy: 0.8278 - val_loss: 0.6260 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4142 - accuracy: 0.8315 - val_loss: 0.6263 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.6258 - val_accuracy: 0.6912 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4304 - accuracy: 0.8167 - val_loss: 0.6257 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4021 - accuracy: 0.8185 - val_loss: 0.6260 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3948 - accuracy: 0.8444 - val_loss: 0.6265 - val_accuracy: 0.6838 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 99ms/step - loss: 0.6946 - accuracy: 0.5234 - val_loss: 0.6878 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.7213 - accuracy: 0.5290 - val_loss: 0.6777 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6844 - accuracy: 0.5514 - val_loss: 0.6744 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6748 - accuracy: 0.5682 - val_loss: 0.6847 - val_accuracy: 0.5821 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6736 - accuracy: 0.5925 - val_loss: 0.6836 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6694 - accuracy: 0.5813 - val_loss: 0.7063 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6742 - accuracy: 0.5963 - val_loss: 0.6299 - val_accuracy: 0.6791 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6429 - accuracy: 0.6075 - val_loss: 0.6324 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6428 - accuracy: 0.6262 - val_loss: 0.6312 - val_accuracy: 0.7090 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6239 - accuracy: 0.6318 - val_loss: 0.6139 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6089 - accuracy: 0.6692 - val_loss: 0.5798 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5965 - accuracy: 0.6766 - val_loss: 0.5785 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5889 - accuracy: 0.6822 - val_loss: 0.5520 - val_accuracy: 0.7090 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5667 - accuracy: 0.7103 - val_loss: 0.5343 - val_accuracy: 0.7388 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5618 - accuracy: 0.7084 - val_loss: 0.5932 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5468 - accuracy: 0.7140 - val_loss: 0.5291 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5355 - accuracy: 0.7215 - val_loss: 0.5356 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5426 - accuracy: 0.7458 - val_loss: 0.5256 - val_accuracy: 0.7612 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4848 - accuracy: 0.7720 - val_loss: 0.4986 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4915 - accuracy: 0.7701 - val_loss: 0.5272 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4900 - accuracy: 0.7645 - val_loss: 0.5515 - val_accuracy: 0.7090 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4266 - accuracy: 0.8000 - val_loss: 0.6248 - val_accuracy: 0.7239 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.4724 - accuracy: 0.7794 - val_loss: 0.5234 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4100 - accuracy: 0.8131 - val_loss: 0.5356 - val_accuracy: 0.7090 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3880 - accuracy: 0.8206 - val_loss: 0.4843 - val_accuracy: 0.7612 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3757 - accuracy: 0.8150 - val_loss: 0.4937 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3753 - accuracy: 0.8336 - val_loss: 0.4882 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3450 - accuracy: 0.8430 - val_loss: 0.5077 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3505 - accuracy: 0.8411 - val_loss: 0.4913 - val_accuracy: 0.7985 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3410 - accuracy: 0.8561 - val_loss: 0.4778 - val_accuracy: 0.7985 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3222 - accuracy: 0.8430 - val_loss: 0.5184 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3120 - accuracy: 0.8710 - val_loss: 0.5026 - val_accuracy: 0.7910 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3340 - accuracy: 0.8617 - val_loss: 0.4801 - val_accuracy: 0.7836 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3428 - accuracy: 0.8523 - val_loss: 0.4744 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3243 - accuracy: 0.8505 - val_loss: 0.4783 - val_accuracy: 0.8060 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2886 - accuracy: 0.8766 - val_loss: 0.4980 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2872 - accuracy: 0.8710 - val_loss: 0.4989 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3083 - accuracy: 0.8710 - val_loss: 0.5485 - val_accuracy: 0.7687 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3108 - accuracy: 0.8692 - val_loss: 0.5400 - val_accuracy: 0.7463 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2979 - accuracy: 0.8710 - val_loss: 0.5147 - val_accuracy: 0.7537 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2614 - accuracy: 0.8935 - val_loss: 0.5033 - val_accuracy: 0.7537 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2718 - accuracy: 0.8673 - val_loss: 0.4945 - val_accuracy: 0.7687 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2803 - accuracy: 0.8897 - val_loss: 0.5099 - val_accuracy: 0.7761 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2556 - accuracy: 0.8860 - val_loss: 0.5086 - val_accuracy: 0.7836 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2423 - accuracy: 0.8897 - val_loss: 0.5178 - val_accuracy: 0.7910 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2547 - accuracy: 0.9047 - val_loss: 0.5127 - val_accuracy: 0.7836 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2431 - accuracy: 0.8991 - val_loss: 0.5201 - val_accuracy: 0.7761 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2364 - accuracy: 0.9047 - val_loss: 0.5306 - val_accuracy: 0.7910 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2444 - accuracy: 0.9028 - val_loss: 0.5262 - val_accuracy: 0.7910 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2449 - accuracy: 0.8972 - val_loss: 0.5229 - val_accuracy: 0.7761 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2373 - accuracy: 0.8953 - val_loss: 0.5304 - val_accuracy: 0.7910 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2016 - accuracy: 0.9196 - val_loss: 0.5395 - val_accuracy: 0.7910 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2237 - accuracy: 0.9121 - val_loss: 0.5319 - val_accuracy: 0.7761 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2366 - accuracy: 0.8991 - val_loss: 0.5314 - val_accuracy: 0.7836 - lr: 6.2500e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2514 - accuracy: 0.8916 - val_loss: 0.5272 - val_accuracy: 0.7761 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2493 - accuracy: 0.8953 - val_loss: 0.5291 - val_accuracy: 0.7836 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2406 - accuracy: 0.8897 - val_loss: 0.5273 - val_accuracy: 0.7761 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2441 - accuracy: 0.8916 - val_loss: 0.5277 - val_accuracy: 0.7761 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2329 - accuracy: 0.9103 - val_loss: 0.5296 - val_accuracy: 0.7761 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2142 - accuracy: 0.9121 - val_loss: 0.5303 - val_accuracy: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2397 - accuracy: 0.8953 - val_loss: 0.5275 - val_accuracy: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2290 - accuracy: 0.9084 - val_loss: 0.5260 - val_accuracy: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2088 - accuracy: 0.9178 - val_loss: 0.5275 - val_accuracy: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.2394 - accuracy: 0.8953 - val_loss: 0.5275 - val_accuracy: 0.7761 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2418 - accuracy: 0.8935 - val_loss: 0.5263 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2300 - accuracy: 0.9009 - val_loss: 0.5266 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2278 - accuracy: 0.8991 - val_loss: 0.5278 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2042 - accuracy: 0.9196 - val_loss: 0.5278 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2476 - accuracy: 0.8991 - val_loss: 0.5274 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2224 - accuracy: 0.8879 - val_loss: 0.5269 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2308 - accuracy: 0.9009 - val_loss: 0.5264 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2161 - accuracy: 0.9103 - val_loss: 0.5255 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2337 - accuracy: 0.9028 - val_loss: 0.5271 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2229 - accuracy: 0.8991 - val_loss: 0.5268 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2146 - accuracy: 0.9065 - val_loss: 0.5279 - val_accuracy: 0.7761 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2420 - accuracy: 0.8953 - val_loss: 0.5270 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2223 - accuracy: 0.9178 - val_loss: 0.5276 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2236 - accuracy: 0.8991 - val_loss: 0.5276 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2252 - accuracy: 0.9009 - val_loss: 0.5279 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2154 - accuracy: 0.9084 - val_loss: 0.5290 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2073 - accuracy: 0.9140 - val_loss: 0.5295 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2221 - accuracy: 0.9121 - val_loss: 0.5304 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2220 - accuracy: 0.9084 - val_loss: 0.5303 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2261 - accuracy: 0.9121 - val_loss: 0.5302 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 102ms/step - loss: 0.7431 - accuracy: 0.5086 - val_loss: 0.6850 - val_accuracy: 0.6364 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6962 - accuracy: 0.4705 - val_loss: 0.6899 - val_accuracy: 0.5606 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.7003 - accuracy: 0.4990 - val_loss: 0.6845 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6958 - accuracy: 0.5333 - val_loss: 0.6775 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6980 - accuracy: 0.5238 - val_loss: 0.6835 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6877 - accuracy: 0.5333 - val_loss: 0.7199 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6806 - accuracy: 0.5733 - val_loss: 0.6532 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6876 - accuracy: 0.5600 - val_loss: 0.6734 - val_accuracy: 0.5606 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6558 - accuracy: 0.6000 - val_loss: 0.6213 - val_accuracy: 0.6364 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6569 - accuracy: 0.6210 - val_loss: 0.6733 - val_accuracy: 0.5379 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6356 - accuracy: 0.6400 - val_loss: 0.6549 - val_accuracy: 0.5227 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6343 - accuracy: 0.6286 - val_loss: 0.6682 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6184 - accuracy: 0.6610 - val_loss: 0.6752 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6019 - accuracy: 0.6648 - val_loss: 0.6746 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5992 - accuracy: 0.6590 - val_loss: 0.6439 - val_accuracy: 0.5758 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5790 - accuracy: 0.6971 - val_loss: 0.6122 - val_accuracy: 0.6136 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.5621 - accuracy: 0.7067 - val_loss: 0.6066 - val_accuracy: 0.6136 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5646 - accuracy: 0.7010 - val_loss: 0.5967 - val_accuracy: 0.6515 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.5598 - accuracy: 0.7105 - val_loss: 0.6314 - val_accuracy: 0.6212 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5445 - accuracy: 0.7314 - val_loss: 0.6216 - val_accuracy: 0.6288 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5199 - accuracy: 0.7524 - val_loss: 0.6315 - val_accuracy: 0.6288 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5383 - accuracy: 0.7257 - val_loss: 0.5719 - val_accuracy: 0.6970 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5086 - accuracy: 0.7448 - val_loss: 0.6348 - val_accuracy: 0.6439 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4987 - accuracy: 0.7638 - val_loss: 0.5942 - val_accuracy: 0.6515 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4989 - accuracy: 0.7676 - val_loss: 0.6107 - val_accuracy: 0.7045 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5103 - accuracy: 0.7448 - val_loss: 0.5685 - val_accuracy: 0.7197 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4771 - accuracy: 0.7867 - val_loss: 0.5875 - val_accuracy: 0.7197 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4887 - accuracy: 0.7733 - val_loss: 0.5600 - val_accuracy: 0.7045 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4864 - accuracy: 0.7676 - val_loss: 0.5565 - val_accuracy: 0.7045 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4701 - accuracy: 0.7810 - val_loss: 0.5513 - val_accuracy: 0.7197 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4604 - accuracy: 0.7790 - val_loss: 0.5608 - val_accuracy: 0.7197 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4770 - accuracy: 0.7886 - val_loss: 0.5481 - val_accuracy: 0.7424 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4640 - accuracy: 0.7905 - val_loss: 0.5156 - val_accuracy: 0.7652 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4479 - accuracy: 0.8038 - val_loss: 0.5488 - val_accuracy: 0.6894 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4274 - accuracy: 0.8305 - val_loss: 0.5713 - val_accuracy: 0.7424 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4409 - accuracy: 0.7924 - val_loss: 0.5365 - val_accuracy: 0.7121 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4410 - accuracy: 0.8000 - val_loss: 0.5429 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4323 - accuracy: 0.8152 - val_loss: 0.5259 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4230 - accuracy: 0.8114 - val_loss: 0.5313 - val_accuracy: 0.7348 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4007 - accuracy: 0.8190 - val_loss: 0.5200 - val_accuracy: 0.7576 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4077 - accuracy: 0.8152 - val_loss: 0.5261 - val_accuracy: 0.7424 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4020 - accuracy: 0.8324 - val_loss: 0.5344 - val_accuracy: 0.7727 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4080 - accuracy: 0.8248 - val_loss: 0.5337 - val_accuracy: 0.7348 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3792 - accuracy: 0.8286 - val_loss: 0.5223 - val_accuracy: 0.7576 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3861 - accuracy: 0.8419 - val_loss: 0.5219 - val_accuracy: 0.7576 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3786 - accuracy: 0.8362 - val_loss: 0.5183 - val_accuracy: 0.7576 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3842 - accuracy: 0.8324 - val_loss: 0.5327 - val_accuracy: 0.7500 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3664 - accuracy: 0.8419 - val_loss: 0.5202 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3645 - accuracy: 0.8324 - val_loss: 0.5227 - val_accuracy: 0.7727 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3652 - accuracy: 0.8438 - val_loss: 0.5223 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3614 - accuracy: 0.8419 - val_loss: 0.5365 - val_accuracy: 0.7727 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3481 - accuracy: 0.8533 - val_loss: 0.5260 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3507 - accuracy: 0.8610 - val_loss: 0.5253 - val_accuracy: 0.7879 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3601 - accuracy: 0.8457 - val_loss: 0.5189 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3442 - accuracy: 0.8781 - val_loss: 0.5176 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3552 - accuracy: 0.8381 - val_loss: 0.5253 - val_accuracy: 0.7727 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3667 - accuracy: 0.8571 - val_loss: 0.5271 - val_accuracy: 0.7652 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3265 - accuracy: 0.8686 - val_loss: 0.5224 - val_accuracy: 0.7576 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3428 - accuracy: 0.8686 - val_loss: 0.5220 - val_accuracy: 0.7576 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3504 - accuracy: 0.8571 - val_loss: 0.5216 - val_accuracy: 0.7652 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3671 - accuracy: 0.8229 - val_loss: 0.5213 - val_accuracy: 0.7652 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3724 - accuracy: 0.8514 - val_loss: 0.5214 - val_accuracy: 0.7652 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3504 - accuracy: 0.8552 - val_loss: 0.5222 - val_accuracy: 0.7576 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.3504 - accuracy: 0.8438 - val_loss: 0.5212 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3657 - accuracy: 0.8438 - val_loss: 0.5211 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3410 - accuracy: 0.8514 - val_loss: 0.5228 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3764 - accuracy: 0.8324 - val_loss: 0.5229 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3380 - accuracy: 0.8552 - val_loss: 0.5227 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3580 - accuracy: 0.8381 - val_loss: 0.5228 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3606 - accuracy: 0.8381 - val_loss: 0.5223 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3469 - accuracy: 0.8438 - val_loss: 0.5235 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3534 - accuracy: 0.8514 - val_loss: 0.5219 - val_accuracy: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3529 - accuracy: 0.8495 - val_loss: 0.5212 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3479 - accuracy: 0.8514 - val_loss: 0.5201 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3368 - accuracy: 0.8686 - val_loss: 0.5196 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3521 - accuracy: 0.8514 - val_loss: 0.5202 - val_accuracy: 0.7652 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3667 - accuracy: 0.8533 - val_loss: 0.5193 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3495 - accuracy: 0.8533 - val_loss: 0.5190 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3754 - accuracy: 0.8438 - val_loss: 0.5193 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3648 - accuracy: 0.8362 - val_loss: 0.5216 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3512 - accuracy: 0.8781 - val_loss: 0.5227 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3316 - accuracy: 0.8629 - val_loss: 0.5228 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3476 - accuracy: 0.8476 - val_loss: 0.5233 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_3((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c88587-9438-42c0-8d2d-f1aa97e25179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.6509\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.7679\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.7818\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6220369-d5d9-44f4-90b0-07d007ce6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}\n",
    "\n",
    "def create_cnn_lstm_4(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "312705b4-f8a1-44d9-90c2-7d14914ad94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 8s 99ms/step - loss: 0.6946 - accuracy: 0.4833 - val_loss: 0.6914 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6933 - accuracy: 0.4907 - val_loss: 0.6887 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6875 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6906 - accuracy: 0.5426 - val_loss: 0.6859 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6901 - accuracy: 0.5407 - val_loss: 0.6847 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6877 - accuracy: 0.5611 - val_loss: 0.6836 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6893 - accuracy: 0.5481 - val_loss: 0.6826 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 0.6878 - accuracy: 0.5519 - val_loss: 0.6817 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6861 - accuracy: 0.5481 - val_loss: 0.6810 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6896 - accuracy: 0.5407 - val_loss: 0.6809 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6882 - accuracy: 0.5519 - val_loss: 0.6805 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6883 - accuracy: 0.5407 - val_loss: 0.6803 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6904 - accuracy: 0.5481 - val_loss: 0.6800 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6883 - accuracy: 0.5481 - val_loss: 0.6795 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6859 - accuracy: 0.5426 - val_loss: 0.6789 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6878 - accuracy: 0.5519 - val_loss: 0.6788 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6888 - accuracy: 0.5407 - val_loss: 0.6784 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6902 - accuracy: 0.5370 - val_loss: 0.6783 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6863 - accuracy: 0.5389 - val_loss: 0.6780 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6886 - accuracy: 0.5463 - val_loss: 0.6779 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6854 - accuracy: 0.5463 - val_loss: 0.6775 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6858 - accuracy: 0.5481 - val_loss: 0.6772 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6892 - accuracy: 0.5444 - val_loss: 0.6772 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6877 - accuracy: 0.5444 - val_loss: 0.6771 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6864 - accuracy: 0.5407 - val_loss: 0.6770 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6829 - accuracy: 0.5500 - val_loss: 0.6766 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6861 - accuracy: 0.5352 - val_loss: 0.6767 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6889 - accuracy: 0.5389 - val_loss: 0.6767 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6874 - accuracy: 0.5519 - val_loss: 0.6766 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6852 - accuracy: 0.5537 - val_loss: 0.6766 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6846 - accuracy: 0.5463 - val_loss: 0.6762 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6873 - accuracy: 0.5333 - val_loss: 0.6763 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6830 - accuracy: 0.5481 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6843 - accuracy: 0.5593 - val_loss: 0.6755 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6856 - accuracy: 0.5481 - val_loss: 0.6755 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6847 - accuracy: 0.5519 - val_loss: 0.6754 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6856 - accuracy: 0.5444 - val_loss: 0.6753 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6850 - accuracy: 0.5500 - val_loss: 0.6750 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6883 - accuracy: 0.5444 - val_loss: 0.6752 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6844 - accuracy: 0.5500 - val_loss: 0.6755 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6855 - accuracy: 0.5426 - val_loss: 0.6759 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6854 - accuracy: 0.5500 - val_loss: 0.6760 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6850 - accuracy: 0.5556 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6895 - accuracy: 0.5407 - val_loss: 0.6759 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6859 - accuracy: 0.5389 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6893 - accuracy: 0.5370 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6838 - accuracy: 0.5519 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6847 - accuracy: 0.5500 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.6842 - accuracy: 0.5500 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.6835 - accuracy: 0.5500 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.6855 - accuracy: 0.5481 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6844 - accuracy: 0.5537 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 2.5000e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6854 - accuracy: 0.5519 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 2.5000e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6871 - accuracy: 0.5370 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6849 - accuracy: 0.5519 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.2500e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.6827 - accuracy: 0.5593 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.2500e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6870 - accuracy: 0.5519 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6848 - accuracy: 0.5407 - val_loss: 0.6758 - val_accuracy: 0.6029 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6871 - accuracy: 0.5537 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 6.2500e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6866 - accuracy: 0.5426 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 6.2500e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6872 - accuracy: 0.5370 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 6.2500e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6845 - accuracy: 0.5463 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 6.2500e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6840 - accuracy: 0.5463 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 6.2500e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6858 - accuracy: 0.5407 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 3.1250e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6847 - accuracy: 0.5463 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 3.1250e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6825 - accuracy: 0.5611 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 3.1250e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6847 - accuracy: 0.5370 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 3.1250e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6817 - accuracy: 0.5537 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 3.1250e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6872 - accuracy: 0.5593 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6840 - accuracy: 0.5630 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6838 - accuracy: 0.5574 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6837 - accuracy: 0.5463 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.5625e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6873 - accuracy: 0.5426 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.5625e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6860 - accuracy: 0.5333 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6813 - accuracy: 0.5667 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6860 - accuracy: 0.5500 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6867 - accuracy: 0.5648 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6842 - accuracy: 0.5352 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6873 - accuracy: 0.5333 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6864 - accuracy: 0.5556 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6844 - accuracy: 0.5426 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6821 - accuracy: 0.5519 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6860 - accuracy: 0.5500 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6858 - accuracy: 0.5500 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6839 - accuracy: 0.5630 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6832 - accuracy: 0.5630 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6808 - accuracy: 0.5519 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6838 - accuracy: 0.5444 - val_loss: 0.6757 - val_accuracy: 0.6029 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 15ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 101ms/step - loss: 0.6853 - accuracy: 0.5607 - val_loss: 0.6835 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6849 - accuracy: 0.5570 - val_loss: 0.6832 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6888 - accuracy: 0.5477 - val_loss: 0.6831 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6875 - accuracy: 0.5570 - val_loss: 0.6829 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6881 - accuracy: 0.5607 - val_loss: 0.6827 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6875 - accuracy: 0.5570 - val_loss: 0.6827 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6854 - accuracy: 0.5645 - val_loss: 0.6825 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6835 - accuracy: 0.5570 - val_loss: 0.6823 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6810 - accuracy: 0.5607 - val_loss: 0.6821 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6875 - accuracy: 0.5495 - val_loss: 0.6820 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6876 - accuracy: 0.5589 - val_loss: 0.6819 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6839 - accuracy: 0.5570 - val_loss: 0.6818 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6807 - accuracy: 0.5570 - val_loss: 0.6816 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6864 - accuracy: 0.5589 - val_loss: 0.6816 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.6856 - accuracy: 0.5551 - val_loss: 0.6814 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6831 - accuracy: 0.5533 - val_loss: 0.6814 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6853 - accuracy: 0.5589 - val_loss: 0.6814 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6829 - accuracy: 0.5589 - val_loss: 0.6812 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6845 - accuracy: 0.5589 - val_loss: 0.6810 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6819 - accuracy: 0.5551 - val_loss: 0.6808 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6821 - accuracy: 0.5589 - val_loss: 0.6807 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6886 - accuracy: 0.5570 - val_loss: 0.6806 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6827 - accuracy: 0.5589 - val_loss: 0.6805 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6831 - accuracy: 0.5551 - val_loss: 0.6803 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6838 - accuracy: 0.5607 - val_loss: 0.6802 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6876 - accuracy: 0.5607 - val_loss: 0.6803 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6820 - accuracy: 0.5589 - val_loss: 0.6801 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6847 - accuracy: 0.5607 - val_loss: 0.6799 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6837 - accuracy: 0.5533 - val_loss: 0.6798 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6822 - accuracy: 0.5589 - val_loss: 0.6798 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6838 - accuracy: 0.5589 - val_loss: 0.6796 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6820 - accuracy: 0.5589 - val_loss: 0.6793 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6810 - accuracy: 0.5514 - val_loss: 0.6792 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6838 - accuracy: 0.5589 - val_loss: 0.6791 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6786 - accuracy: 0.5626 - val_loss: 0.6788 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6806 - accuracy: 0.5514 - val_loss: 0.6786 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6797 - accuracy: 0.5589 - val_loss: 0.6784 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6886 - accuracy: 0.5477 - val_loss: 0.6783 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6798 - accuracy: 0.5551 - val_loss: 0.6781 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6792 - accuracy: 0.5551 - val_loss: 0.6781 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6780 - accuracy: 0.5664 - val_loss: 0.6780 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6818 - accuracy: 0.5589 - val_loss: 0.6779 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6805 - accuracy: 0.5645 - val_loss: 0.6776 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6804 - accuracy: 0.5477 - val_loss: 0.6773 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6783 - accuracy: 0.5738 - val_loss: 0.6770 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6819 - accuracy: 0.5626 - val_loss: 0.6769 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6801 - accuracy: 0.5664 - val_loss: 0.6769 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6795 - accuracy: 0.5570 - val_loss: 0.6767 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6784 - accuracy: 0.5533 - val_loss: 0.6762 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6772 - accuracy: 0.5626 - val_loss: 0.6760 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6789 - accuracy: 0.5720 - val_loss: 0.6759 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6789 - accuracy: 0.5626 - val_loss: 0.6757 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6785 - accuracy: 0.5626 - val_loss: 0.6755 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6773 - accuracy: 0.5570 - val_loss: 0.6753 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6796 - accuracy: 0.5664 - val_loss: 0.6751 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6778 - accuracy: 0.5570 - val_loss: 0.6750 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6783 - accuracy: 0.5664 - val_loss: 0.6747 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6784 - accuracy: 0.5514 - val_loss: 0.6746 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6820 - accuracy: 0.5551 - val_loss: 0.6746 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6748 - accuracy: 0.5664 - val_loss: 0.6744 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6735 - accuracy: 0.5720 - val_loss: 0.6741 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6812 - accuracy: 0.5570 - val_loss: 0.6740 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6796 - accuracy: 0.5701 - val_loss: 0.6738 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6756 - accuracy: 0.5664 - val_loss: 0.6736 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6789 - accuracy: 0.5570 - val_loss: 0.6733 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6787 - accuracy: 0.5738 - val_loss: 0.6731 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6740 - accuracy: 0.5701 - val_loss: 0.6730 - val_accuracy: 0.5448 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6769 - accuracy: 0.5551 - val_loss: 0.6728 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6767 - accuracy: 0.5364 - val_loss: 0.6727 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6777 - accuracy: 0.5477 - val_loss: 0.6727 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6776 - accuracy: 0.5570 - val_loss: 0.6726 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6782 - accuracy: 0.5682 - val_loss: 0.6724 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6806 - accuracy: 0.5664 - val_loss: 0.6722 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6796 - accuracy: 0.5589 - val_loss: 0.6721 - val_accuracy: 0.5746 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6785 - accuracy: 0.5645 - val_loss: 0.6718 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6716 - accuracy: 0.5701 - val_loss: 0.6717 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6777 - accuracy: 0.5701 - val_loss: 0.6715 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6723 - accuracy: 0.5495 - val_loss: 0.6713 - val_accuracy: 0.5522 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6737 - accuracy: 0.5720 - val_loss: 0.6711 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6740 - accuracy: 0.5720 - val_loss: 0.6709 - val_accuracy: 0.5821 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6753 - accuracy: 0.5495 - val_loss: 0.6708 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6764 - accuracy: 0.5589 - val_loss: 0.6706 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6739 - accuracy: 0.5607 - val_loss: 0.6704 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6752 - accuracy: 0.5869 - val_loss: 0.6705 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6777 - accuracy: 0.5327 - val_loss: 0.6701 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6728 - accuracy: 0.5944 - val_loss: 0.6699 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6773 - accuracy: 0.5701 - val_loss: 0.6699 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6717 - accuracy: 0.5645 - val_loss: 0.6698 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6725 - accuracy: 0.5682 - val_loss: 0.6694 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6782 - accuracy: 0.5626 - val_loss: 0.6695 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6715 - accuracy: 0.5682 - val_loss: 0.6692 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6758 - accuracy: 0.5720 - val_loss: 0.6689 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6730 - accuracy: 0.5664 - val_loss: 0.6687 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6713 - accuracy: 0.6000 - val_loss: 0.6685 - val_accuracy: 0.5896 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6749 - accuracy: 0.5570 - val_loss: 0.6684 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6756 - accuracy: 0.5477 - val_loss: 0.6682 - val_accuracy: 0.6045 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6715 - accuracy: 0.5645 - val_loss: 0.6680 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6754 - accuracy: 0.5794 - val_loss: 0.6679 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6726 - accuracy: 0.5813 - val_loss: 0.6679 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6745 - accuracy: 0.5813 - val_loss: 0.6678 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 5s 101ms/step - loss: 0.6924 - accuracy: 0.4933 - val_loss: 0.6888 - val_accuracy: 0.5530 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6935 - accuracy: 0.4952 - val_loss: 0.6892 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6926 - accuracy: 0.5390 - val_loss: 0.6880 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6856 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6917 - accuracy: 0.5029 - val_loss: 0.6834 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6885 - accuracy: 0.5524 - val_loss: 0.6831 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6917 - accuracy: 0.5162 - val_loss: 0.6819 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6913 - accuracy: 0.4971 - val_loss: 0.6816 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6812 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6899 - accuracy: 0.5505 - val_loss: 0.6808 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6900 - accuracy: 0.5257 - val_loss: 0.6800 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6809 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6906 - accuracy: 0.5410 - val_loss: 0.6787 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6912 - accuracy: 0.5238 - val_loss: 0.6786 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6919 - accuracy: 0.5143 - val_loss: 0.6795 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6929 - accuracy: 0.5333 - val_loss: 0.6788 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6885 - accuracy: 0.5257 - val_loss: 0.6781 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6905 - accuracy: 0.5276 - val_loss: 0.6781 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6885 - accuracy: 0.5390 - val_loss: 0.6778 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6910 - accuracy: 0.5333 - val_loss: 0.6782 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6783 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6895 - accuracy: 0.5295 - val_loss: 0.6779 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6883 - accuracy: 0.5619 - val_loss: 0.6779 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6881 - accuracy: 0.5638 - val_loss: 0.6777 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6886 - accuracy: 0.5543 - val_loss: 0.6780 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6890 - accuracy: 0.5390 - val_loss: 0.6774 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6900 - accuracy: 0.5238 - val_loss: 0.6790 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6900 - accuracy: 0.5410 - val_loss: 0.6793 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6883 - accuracy: 0.5581 - val_loss: 0.6787 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.6880 - accuracy: 0.5524 - val_loss: 0.6787 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6873 - accuracy: 0.5390 - val_loss: 0.6786 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6879 - accuracy: 0.5352 - val_loss: 0.6788 - val_accuracy: 0.5758 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6866 - accuracy: 0.5562 - val_loss: 0.6782 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6898 - accuracy: 0.5467 - val_loss: 0.6776 - val_accuracy: 0.6061 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6910 - accuracy: 0.5352 - val_loss: 0.6778 - val_accuracy: 0.5985 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6882 - accuracy: 0.5371 - val_loss: 0.6774 - val_accuracy: 0.6061 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6877 - accuracy: 0.5295 - val_loss: 0.6774 - val_accuracy: 0.6061 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6904 - accuracy: 0.5371 - val_loss: 0.6773 - val_accuracy: 0.6061 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6891 - accuracy: 0.5257 - val_loss: 0.6772 - val_accuracy: 0.6061 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6898 - accuracy: 0.5333 - val_loss: 0.6775 - val_accuracy: 0.5985 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6886 - accuracy: 0.5219 - val_loss: 0.6774 - val_accuracy: 0.5985 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6904 - accuracy: 0.5181 - val_loss: 0.6778 - val_accuracy: 0.5909 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6907 - accuracy: 0.5486 - val_loss: 0.6778 - val_accuracy: 0.5985 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6913 - accuracy: 0.5467 - val_loss: 0.6779 - val_accuracy: 0.5833 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6916 - accuracy: 0.5257 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6877 - accuracy: 0.5676 - val_loss: 0.6779 - val_accuracy: 0.5833 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6870 - accuracy: 0.5676 - val_loss: 0.6779 - val_accuracy: 0.5833 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.6873 - accuracy: 0.5695 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6886 - accuracy: 0.5295 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6892 - accuracy: 0.5448 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6885 - accuracy: 0.5314 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6881 - accuracy: 0.5410 - val_loss: 0.6783 - val_accuracy: 0.5758 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6892 - accuracy: 0.5410 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6895 - accuracy: 0.5448 - val_loss: 0.6783 - val_accuracy: 0.5758 - lr: 6.2500e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6866 - accuracy: 0.5333 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6889 - accuracy: 0.5771 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6880 - accuracy: 0.5333 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6880 - accuracy: 0.5505 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6900 - accuracy: 0.5162 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6893 - accuracy: 0.5371 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6884 - accuracy: 0.5219 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.6905 - accuracy: 0.5295 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6909 - accuracy: 0.5390 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6889 - accuracy: 0.5429 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6852 - accuracy: 0.5619 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6873 - accuracy: 0.5390 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6884 - accuracy: 0.5276 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6875 - accuracy: 0.5486 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6869 - accuracy: 0.5505 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6873 - accuracy: 0.5505 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6890 - accuracy: 0.5410 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6882 - accuracy: 0.5467 - val_loss: 0.6782 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6889 - accuracy: 0.5390 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6872 - accuracy: 0.5505 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6870 - accuracy: 0.5314 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6891 - accuracy: 0.5314 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6883 - accuracy: 0.5371 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6886 - accuracy: 0.5390 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6882 - accuracy: 0.5562 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6886 - accuracy: 0.5257 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6866 - accuracy: 0.5581 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6887 - accuracy: 0.5200 - val_loss: 0.6781 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6874 - accuracy: 0.5486 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6876 - accuracy: 0.5657 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6878 - accuracy: 0.5486 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6895 - accuracy: 0.4990 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6886 - accuracy: 0.5524 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6882 - accuracy: 0.5486 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6876 - accuracy: 0.5543 - val_loss: 0.6781 - val_accuracy: 0.5758 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_4((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86e596ca-27c2-4be8-853f-227818dd2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.5325\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.5774\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.6121\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96968635-db1e-424d-9c6b-9ebb27befed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}\n",
    "\n",
    "def create_cnn_lstm_5(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "225651db-32d8-4b99-a8f0-0a1930135468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 108ms/step - loss: 0.6970 - accuracy: 0.5204 - val_loss: 0.6818 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6792 - accuracy: 0.5685 - val_loss: 0.6681 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6902 - accuracy: 0.5296 - val_loss: 0.6699 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6837 - accuracy: 0.5759 - val_loss: 0.6702 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6761 - accuracy: 0.5889 - val_loss: 0.6630 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6763 - accuracy: 0.5759 - val_loss: 0.6533 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6731 - accuracy: 0.5685 - val_loss: 0.6650 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6670 - accuracy: 0.6019 - val_loss: 0.6499 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6615 - accuracy: 0.6074 - val_loss: 0.6657 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6517 - accuracy: 0.6148 - val_loss: 0.6354 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6478 - accuracy: 0.6130 - val_loss: 0.6492 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6431 - accuracy: 0.6315 - val_loss: 0.6494 - val_accuracy: 0.6103 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6303 - accuracy: 0.6648 - val_loss: 0.6529 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6195 - accuracy: 0.6722 - val_loss: 0.6434 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6052 - accuracy: 0.6593 - val_loss: 0.6465 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6136 - accuracy: 0.6519 - val_loss: 0.6417 - val_accuracy: 0.6397 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6092 - accuracy: 0.6593 - val_loss: 0.6377 - val_accuracy: 0.6471 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6086 - accuracy: 0.6630 - val_loss: 0.6338 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5923 - accuracy: 0.6852 - val_loss: 0.6461 - val_accuracy: 0.6324 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5930 - accuracy: 0.6963 - val_loss: 0.6308 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5868 - accuracy: 0.6981 - val_loss: 0.6425 - val_accuracy: 0.6471 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5783 - accuracy: 0.6963 - val_loss: 0.6342 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5603 - accuracy: 0.7000 - val_loss: 0.6416 - val_accuracy: 0.6397 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5721 - accuracy: 0.7000 - val_loss: 0.6247 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5725 - accuracy: 0.7037 - val_loss: 0.6381 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5447 - accuracy: 0.7444 - val_loss: 0.6308 - val_accuracy: 0.6471 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5602 - accuracy: 0.7296 - val_loss: 0.6445 - val_accuracy: 0.6397 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5396 - accuracy: 0.7259 - val_loss: 0.6182 - val_accuracy: 0.6618 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5534 - accuracy: 0.7056 - val_loss: 0.6246 - val_accuracy: 0.6912 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5279 - accuracy: 0.7426 - val_loss: 0.6174 - val_accuracy: 0.6544 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5134 - accuracy: 0.7481 - val_loss: 0.6186 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5040 - accuracy: 0.7556 - val_loss: 0.6211 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.5033 - accuracy: 0.7370 - val_loss: 0.6129 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4805 - accuracy: 0.7907 - val_loss: 0.6340 - val_accuracy: 0.6765 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4740 - accuracy: 0.7648 - val_loss: 0.6154 - val_accuracy: 0.6912 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4754 - accuracy: 0.7611 - val_loss: 0.6225 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4828 - accuracy: 0.7648 - val_loss: 0.6246 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.6157 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4595 - accuracy: 0.7852 - val_loss: 0.6323 - val_accuracy: 0.6765 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4528 - accuracy: 0.7722 - val_loss: 0.6222 - val_accuracy: 0.6912 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4587 - accuracy: 0.7815 - val_loss: 0.6175 - val_accuracy: 0.7059 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4347 - accuracy: 0.8130 - val_loss: 0.6244 - val_accuracy: 0.7206 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4473 - accuracy: 0.8000 - val_loss: 0.6174 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4363 - accuracy: 0.8130 - val_loss: 0.6250 - val_accuracy: 0.7132 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4361 - accuracy: 0.7944 - val_loss: 0.6287 - val_accuracy: 0.7059 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4446 - accuracy: 0.7889 - val_loss: 0.6225 - val_accuracy: 0.7132 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.6214 - val_accuracy: 0.7279 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4457 - accuracy: 0.7981 - val_loss: 0.6187 - val_accuracy: 0.7132 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4486 - accuracy: 0.8037 - val_loss: 0.6186 - val_accuracy: 0.7279 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4273 - accuracy: 0.8148 - val_loss: 0.6167 - val_accuracy: 0.7279 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4118 - accuracy: 0.8093 - val_loss: 0.6156 - val_accuracy: 0.7279 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4595 - accuracy: 0.7889 - val_loss: 0.6142 - val_accuracy: 0.7279 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4328 - accuracy: 0.7944 - val_loss: 0.6162 - val_accuracy: 0.7279 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4349 - accuracy: 0.8111 - val_loss: 0.6164 - val_accuracy: 0.7279 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4506 - accuracy: 0.7944 - val_loss: 0.6157 - val_accuracy: 0.7353 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4391 - accuracy: 0.8019 - val_loss: 0.6145 - val_accuracy: 0.7279 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4224 - accuracy: 0.8093 - val_loss: 0.6157 - val_accuracy: 0.7279 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4382 - accuracy: 0.7907 - val_loss: 0.6156 - val_accuracy: 0.7279 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4290 - accuracy: 0.8000 - val_loss: 0.6159 - val_accuracy: 0.7279 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4309 - accuracy: 0.8019 - val_loss: 0.6156 - val_accuracy: 0.7353 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3952 - accuracy: 0.8407 - val_loss: 0.6151 - val_accuracy: 0.7353 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4200 - accuracy: 0.8074 - val_loss: 0.6152 - val_accuracy: 0.7353 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4289 - accuracy: 0.7963 - val_loss: 0.6158 - val_accuracy: 0.7353 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4298 - accuracy: 0.7907 - val_loss: 0.6162 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4241 - accuracy: 0.8000 - val_loss: 0.6165 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4213 - accuracy: 0.8019 - val_loss: 0.6164 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4380 - accuracy: 0.7944 - val_loss: 0.6163 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4088 - accuracy: 0.8148 - val_loss: 0.6162 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4336 - accuracy: 0.7944 - val_loss: 0.6163 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4360 - accuracy: 0.8000 - val_loss: 0.6160 - val_accuracy: 0.7353 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4338 - accuracy: 0.7889 - val_loss: 0.6159 - val_accuracy: 0.7353 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.4179 - accuracy: 0.8222 - val_loss: 0.6159 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4358 - accuracy: 0.7963 - val_loss: 0.6160 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4043 - accuracy: 0.8185 - val_loss: 0.6161 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4240 - accuracy: 0.8019 - val_loss: 0.6164 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4104 - accuracy: 0.8259 - val_loss: 0.6163 - val_accuracy: 0.7353 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4329 - accuracy: 0.7889 - val_loss: 0.6166 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4234 - accuracy: 0.8148 - val_loss: 0.6159 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4107 - accuracy: 0.7926 - val_loss: 0.6156 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4308 - accuracy: 0.7981 - val_loss: 0.6156 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4311 - accuracy: 0.8111 - val_loss: 0.6154 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4271 - accuracy: 0.8093 - val_loss: 0.6159 - val_accuracy: 0.7279 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4268 - accuracy: 0.7889 - val_loss: 0.6160 - val_accuracy: 0.7353 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 9ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 103ms/step - loss: 0.6915 - accuracy: 0.5757 - val_loss: 0.6853 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6865 - accuracy: 0.5421 - val_loss: 0.6768 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6838 - accuracy: 0.5421 - val_loss: 0.6733 - val_accuracy: 0.5299 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.6763 - accuracy: 0.5757 - val_loss: 0.6705 - val_accuracy: 0.6045 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6713 - accuracy: 0.5645 - val_loss: 0.6649 - val_accuracy: 0.6269 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6672 - accuracy: 0.5607 - val_loss: 0.6674 - val_accuracy: 0.6194 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6674 - accuracy: 0.6037 - val_loss: 0.6582 - val_accuracy: 0.6418 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6587 - accuracy: 0.5869 - val_loss: 0.6535 - val_accuracy: 0.6343 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6571 - accuracy: 0.6056 - val_loss: 0.6495 - val_accuracy: 0.6343 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6497 - accuracy: 0.6280 - val_loss: 0.6452 - val_accuracy: 0.6343 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6332 - accuracy: 0.6243 - val_loss: 0.6189 - val_accuracy: 0.6642 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6315 - accuracy: 0.6280 - val_loss: 0.6268 - val_accuracy: 0.6343 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6364 - accuracy: 0.6075 - val_loss: 0.6253 - val_accuracy: 0.6642 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6274 - accuracy: 0.6486 - val_loss: 0.6064 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6171 - accuracy: 0.6766 - val_loss: 0.6062 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6123 - accuracy: 0.6598 - val_loss: 0.6048 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6018 - accuracy: 0.6654 - val_loss: 0.5952 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6020 - accuracy: 0.6729 - val_loss: 0.5821 - val_accuracy: 0.7164 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5937 - accuracy: 0.6710 - val_loss: 0.5769 - val_accuracy: 0.6866 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5983 - accuracy: 0.6785 - val_loss: 0.5684 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5765 - accuracy: 0.7103 - val_loss: 0.5671 - val_accuracy: 0.7239 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5636 - accuracy: 0.6991 - val_loss: 0.5503 - val_accuracy: 0.7239 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5666 - accuracy: 0.7215 - val_loss: 0.5476 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5586 - accuracy: 0.7271 - val_loss: 0.5386 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5705 - accuracy: 0.6991 - val_loss: 0.5356 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5420 - accuracy: 0.7327 - val_loss: 0.5290 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5349 - accuracy: 0.7271 - val_loss: 0.4982 - val_accuracy: 0.7388 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5374 - accuracy: 0.7159 - val_loss: 0.4905 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5146 - accuracy: 0.7589 - val_loss: 0.5192 - val_accuracy: 0.7612 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5031 - accuracy: 0.7514 - val_loss: 0.5029 - val_accuracy: 0.7612 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4961 - accuracy: 0.7589 - val_loss: 0.4689 - val_accuracy: 0.7985 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4708 - accuracy: 0.7794 - val_loss: 0.4648 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4673 - accuracy: 0.7832 - val_loss: 0.4557 - val_accuracy: 0.8134 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4702 - accuracy: 0.7776 - val_loss: 0.4706 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4638 - accuracy: 0.8000 - val_loss: 0.4731 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4423 - accuracy: 0.7944 - val_loss: 0.4777 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4592 - accuracy: 0.7738 - val_loss: 0.4359 - val_accuracy: 0.8209 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4347 - accuracy: 0.7925 - val_loss: 0.4719 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.4763 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4136 - accuracy: 0.8206 - val_loss: 0.4538 - val_accuracy: 0.8134 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4161 - accuracy: 0.8075 - val_loss: 0.4558 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4151 - accuracy: 0.8243 - val_loss: 0.4625 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3863 - accuracy: 0.8430 - val_loss: 0.4523 - val_accuracy: 0.7985 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3758 - accuracy: 0.8374 - val_loss: 0.4287 - val_accuracy: 0.8134 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3766 - accuracy: 0.8374 - val_loss: 0.4346 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3697 - accuracy: 0.8224 - val_loss: 0.4346 - val_accuracy: 0.7910 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3611 - accuracy: 0.8355 - val_loss: 0.4453 - val_accuracy: 0.7836 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3943 - accuracy: 0.8262 - val_loss: 0.4370 - val_accuracy: 0.8060 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3343 - accuracy: 0.8579 - val_loss: 0.4370 - val_accuracy: 0.7836 - lr: 5.0000e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3465 - accuracy: 0.8542 - val_loss: 0.4267 - val_accuracy: 0.7985 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3881 - accuracy: 0.8318 - val_loss: 0.4258 - val_accuracy: 0.8134 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3697 - accuracy: 0.8411 - val_loss: 0.4158 - val_accuracy: 0.8209 - lr: 2.5000e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3465 - accuracy: 0.8579 - val_loss: 0.4352 - val_accuracy: 0.7985 - lr: 2.5000e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3425 - accuracy: 0.8467 - val_loss: 0.4186 - val_accuracy: 0.8284 - lr: 2.5000e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3392 - accuracy: 0.8673 - val_loss: 0.4285 - val_accuracy: 0.8134 - lr: 2.5000e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3452 - accuracy: 0.8617 - val_loss: 0.4329 - val_accuracy: 0.7985 - lr: 2.5000e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3406 - accuracy: 0.8673 - val_loss: 0.4207 - val_accuracy: 0.8134 - lr: 2.5000e-04\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3188 - accuracy: 0.8804 - val_loss: 0.4221 - val_accuracy: 0.8433 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3510 - accuracy: 0.8449 - val_loss: 0.4336 - val_accuracy: 0.8060 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3279 - accuracy: 0.8598 - val_loss: 0.4222 - val_accuracy: 0.8060 - lr: 1.2500e-04\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3130 - accuracy: 0.8785 - val_loss: 0.4203 - val_accuracy: 0.8134 - lr: 1.2500e-04\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3414 - accuracy: 0.8636 - val_loss: 0.4202 - val_accuracy: 0.8134 - lr: 1.2500e-04\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3489 - accuracy: 0.8579 - val_loss: 0.4231 - val_accuracy: 0.8284 - lr: 6.2500e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3191 - accuracy: 0.8766 - val_loss: 0.4204 - val_accuracy: 0.8209 - lr: 6.2500e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3290 - accuracy: 0.8430 - val_loss: 0.4218 - val_accuracy: 0.8209 - lr: 6.2500e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3411 - accuracy: 0.8486 - val_loss: 0.4269 - val_accuracy: 0.8134 - lr: 6.2500e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3111 - accuracy: 0.8748 - val_loss: 0.4231 - val_accuracy: 0.8134 - lr: 6.2500e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3090 - accuracy: 0.8822 - val_loss: 0.4233 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3318 - accuracy: 0.8579 - val_loss: 0.4218 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3281 - accuracy: 0.8579 - val_loss: 0.4182 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3121 - accuracy: 0.8598 - val_loss: 0.4208 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3429 - accuracy: 0.8579 - val_loss: 0.4201 - val_accuracy: 0.8134 - lr: 3.1250e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3264 - accuracy: 0.8598 - val_loss: 0.4190 - val_accuracy: 0.8284 - lr: 1.5625e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3194 - accuracy: 0.8579 - val_loss: 0.4197 - val_accuracy: 0.8284 - lr: 1.5625e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3370 - accuracy: 0.8561 - val_loss: 0.4209 - val_accuracy: 0.8060 - lr: 1.5625e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3248 - accuracy: 0.8766 - val_loss: 0.4221 - val_accuracy: 0.8134 - lr: 1.5625e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3122 - accuracy: 0.8636 - val_loss: 0.4225 - val_accuracy: 0.8134 - lr: 1.5625e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3292 - accuracy: 0.8766 - val_loss: 0.4224 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3176 - accuracy: 0.8636 - val_loss: 0.4221 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3322 - accuracy: 0.8617 - val_loss: 0.4235 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3045 - accuracy: 0.8822 - val_loss: 0.4236 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3230 - accuracy: 0.8579 - val_loss: 0.4240 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3320 - accuracy: 0.8523 - val_loss: 0.4236 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3348 - accuracy: 0.8673 - val_loss: 0.4223 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3175 - accuracy: 0.8636 - val_loss: 0.4216 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3356 - accuracy: 0.8486 - val_loss: 0.4208 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3112 - accuracy: 0.8673 - val_loss: 0.4204 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3428 - accuracy: 0.8355 - val_loss: 0.4212 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3365 - accuracy: 0.8449 - val_loss: 0.4226 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3261 - accuracy: 0.8636 - val_loss: 0.4230 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3327 - accuracy: 0.8579 - val_loss: 0.4218 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3163 - accuracy: 0.8579 - val_loss: 0.4210 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.3421 - accuracy: 0.8654 - val_loss: 0.4199 - val_accuracy: 0.8284 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3281 - accuracy: 0.8542 - val_loss: 0.4207 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3193 - accuracy: 0.8673 - val_loss: 0.4211 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3258 - accuracy: 0.8617 - val_loss: 0.4216 - val_accuracy: 0.8209 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3364 - accuracy: 0.8673 - val_loss: 0.4230 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3206 - accuracy: 0.8542 - val_loss: 0.4223 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3402 - accuracy: 0.8505 - val_loss: 0.4225 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3410 - accuracy: 0.8430 - val_loss: 0.4221 - val_accuracy: 0.8134 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 13ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 9s 101ms/step - loss: 0.7001 - accuracy: 0.5219 - val_loss: 0.6848 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6899 - accuracy: 0.5257 - val_loss: 0.6757 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6948 - accuracy: 0.5257 - val_loss: 0.7079 - val_accuracy: 0.4470 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6880 - accuracy: 0.5429 - val_loss: 0.6701 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6916 - accuracy: 0.5048 - val_loss: 0.6719 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6836 - accuracy: 0.5600 - val_loss: 0.6893 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6871 - accuracy: 0.5238 - val_loss: 0.6842 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6834 - accuracy: 0.5543 - val_loss: 0.6706 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6757 - accuracy: 0.5848 - val_loss: 0.6677 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6690 - accuracy: 0.6095 - val_loss: 0.6657 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6619 - accuracy: 0.5714 - val_loss: 0.6471 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6577 - accuracy: 0.6210 - val_loss: 0.6617 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6531 - accuracy: 0.6210 - val_loss: 0.6589 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6437 - accuracy: 0.6095 - val_loss: 0.6446 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6382 - accuracy: 0.6248 - val_loss: 0.6392 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6303 - accuracy: 0.6381 - val_loss: 0.6265 - val_accuracy: 0.6288 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6205 - accuracy: 0.6571 - val_loss: 0.6562 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6173 - accuracy: 0.6552 - val_loss: 0.6425 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6040 - accuracy: 0.6629 - val_loss: 0.6415 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.6065 - accuracy: 0.6457 - val_loss: 0.6352 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5933 - accuracy: 0.7048 - val_loss: 0.6180 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5794 - accuracy: 0.6705 - val_loss: 0.6286 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5931 - accuracy: 0.6857 - val_loss: 0.6408 - val_accuracy: 0.6742 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5554 - accuracy: 0.7238 - val_loss: 0.6188 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5593 - accuracy: 0.7010 - val_loss: 0.6119 - val_accuracy: 0.6818 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5476 - accuracy: 0.7200 - val_loss: 0.6036 - val_accuracy: 0.6591 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5392 - accuracy: 0.7124 - val_loss: 0.5998 - val_accuracy: 0.7045 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5446 - accuracy: 0.7200 - val_loss: 0.6132 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5302 - accuracy: 0.7486 - val_loss: 0.6347 - val_accuracy: 0.7121 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5343 - accuracy: 0.7200 - val_loss: 0.5975 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.5374 - accuracy: 0.7410 - val_loss: 0.6100 - val_accuracy: 0.6742 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5471 - accuracy: 0.7105 - val_loss: 0.5756 - val_accuracy: 0.7197 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5353 - accuracy: 0.7314 - val_loss: 0.6085 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5229 - accuracy: 0.7448 - val_loss: 0.5832 - val_accuracy: 0.7121 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5171 - accuracy: 0.7467 - val_loss: 0.5522 - val_accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4892 - accuracy: 0.7714 - val_loss: 0.5696 - val_accuracy: 0.7727 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.5123 - accuracy: 0.7467 - val_loss: 0.5655 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4852 - accuracy: 0.7714 - val_loss: 0.5726 - val_accuracy: 0.7803 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4894 - accuracy: 0.7752 - val_loss: 0.5873 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4847 - accuracy: 0.7905 - val_loss: 0.5473 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4766 - accuracy: 0.7867 - val_loss: 0.5873 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4853 - accuracy: 0.7771 - val_loss: 0.5519 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4753 - accuracy: 0.7867 - val_loss: 0.5456 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4737 - accuracy: 0.7905 - val_loss: 0.5697 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4585 - accuracy: 0.7924 - val_loss: 0.5471 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4632 - accuracy: 0.7924 - val_loss: 0.5653 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4647 - accuracy: 0.7810 - val_loss: 0.5685 - val_accuracy: 0.7803 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4531 - accuracy: 0.7829 - val_loss: 0.5531 - val_accuracy: 0.7727 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4352 - accuracy: 0.8114 - val_loss: 0.5581 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4107 - accuracy: 0.8286 - val_loss: 0.5713 - val_accuracy: 0.7652 - lr: 5.0000e-04\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.4361 - accuracy: 0.7867 - val_loss: 0.5455 - val_accuracy: 0.7879 - lr: 5.0000e-04\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.4164 - accuracy: 0.8210 - val_loss: 0.5630 - val_accuracy: 0.7803 - lr: 5.0000e-04\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.4155 - accuracy: 0.7981 - val_loss: 0.5487 - val_accuracy: 0.7803 - lr: 5.0000e-04\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3953 - accuracy: 0.8248 - val_loss: 0.5528 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.4043 - accuracy: 0.8286 - val_loss: 0.5525 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3983 - accuracy: 0.8419 - val_loss: 0.5518 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3897 - accuracy: 0.8362 - val_loss: 0.5420 - val_accuracy: 0.7955 - lr: 2.5000e-04\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3864 - accuracy: 0.8514 - val_loss: 0.5500 - val_accuracy: 0.7955 - lr: 2.5000e-04\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3869 - accuracy: 0.8171 - val_loss: 0.5515 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3770 - accuracy: 0.8324 - val_loss: 0.5590 - val_accuracy: 0.7727 - lr: 2.5000e-04\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3838 - accuracy: 0.8381 - val_loss: 0.5587 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3892 - accuracy: 0.8171 - val_loss: 0.5478 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3826 - accuracy: 0.8248 - val_loss: 0.5514 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3737 - accuracy: 0.8419 - val_loss: 0.5545 - val_accuracy: 0.7803 - lr: 1.2500e-04\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3999 - accuracy: 0.8305 - val_loss: 0.5378 - val_accuracy: 0.8030 - lr: 1.2500e-04\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3822 - accuracy: 0.8324 - val_loss: 0.5446 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3750 - accuracy: 0.8400 - val_loss: 0.5585 - val_accuracy: 0.7803 - lr: 1.2500e-04\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3840 - accuracy: 0.8190 - val_loss: 0.5468 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3613 - accuracy: 0.8533 - val_loss: 0.5462 - val_accuracy: 0.7803 - lr: 1.2500e-04\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3870 - accuracy: 0.8305 - val_loss: 0.5560 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3811 - accuracy: 0.8248 - val_loss: 0.5542 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3714 - accuracy: 0.8381 - val_loss: 0.5521 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3775 - accuracy: 0.8305 - val_loss: 0.5529 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3661 - accuracy: 0.8495 - val_loss: 0.5528 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3625 - accuracy: 0.8648 - val_loss: 0.5569 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3507 - accuracy: 0.8610 - val_loss: 0.5582 - val_accuracy: 0.7727 - lr: 3.1250e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4002 - accuracy: 0.8248 - val_loss: 0.5555 - val_accuracy: 0.7803 - lr: 3.1250e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3665 - accuracy: 0.8305 - val_loss: 0.5534 - val_accuracy: 0.7727 - lr: 3.1250e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3593 - accuracy: 0.8571 - val_loss: 0.5502 - val_accuracy: 0.7727 - lr: 3.1250e-05\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3656 - accuracy: 0.8476 - val_loss: 0.5500 - val_accuracy: 0.7803 - lr: 3.1250e-05\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3716 - accuracy: 0.8438 - val_loss: 0.5503 - val_accuracy: 0.7803 - lr: 1.5625e-05\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3631 - accuracy: 0.8400 - val_loss: 0.5500 - val_accuracy: 0.7803 - lr: 1.5625e-05\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3677 - accuracy: 0.8571 - val_loss: 0.5496 - val_accuracy: 0.7803 - lr: 1.5625e-05\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3797 - accuracy: 0.8324 - val_loss: 0.5503 - val_accuracy: 0.7803 - lr: 1.5625e-05\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3752 - accuracy: 0.8229 - val_loss: 0.5517 - val_accuracy: 0.7727 - lr: 1.5625e-05\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3902 - accuracy: 0.8210 - val_loss: 0.5503 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3647 - accuracy: 0.8419 - val_loss: 0.5496 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3535 - accuracy: 0.8343 - val_loss: 0.5492 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3655 - accuracy: 0.8610 - val_loss: 0.5493 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3859 - accuracy: 0.8171 - val_loss: 0.5499 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3578 - accuracy: 0.8590 - val_loss: 0.5501 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3659 - accuracy: 0.8457 - val_loss: 0.5505 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3622 - accuracy: 0.8343 - val_loss: 0.5509 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3766 - accuracy: 0.8324 - val_loss: 0.5510 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3709 - accuracy: 0.8438 - val_loss: 0.5488 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3773 - accuracy: 0.8286 - val_loss: 0.5483 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3747 - accuracy: 0.8457 - val_loss: 0.5481 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3756 - accuracy: 0.8381 - val_loss: 0.5473 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3792 - accuracy: 0.8381 - val_loss: 0.5468 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.3739 - accuracy: 0.8286 - val_loss: 0.5466 - val_accuracy: 0.7803 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_5((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06644431-69da-4c3c-a0b8-2fac6adf2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.6509\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.7798\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "148a9e24-aa0d-420f-bfbc-3e8f556cfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个标签的准确率\n",
    "accuracies = {label: [] for label in label_columns}\n",
    "\n",
    "def create_cnn_lstm_6(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN部分\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM部分\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate(axis=-1)([x, attention])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4794558a-d854-4e74-9c9f-10ed20a4f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 7s 101ms/step - loss: 0.6923 - accuracy: 0.5370 - val_loss: 0.6676 - val_accuracy: 0.6103 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6823 - accuracy: 0.5519 - val_loss: 0.6598 - val_accuracy: 0.5882 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6769 - accuracy: 0.5574 - val_loss: 0.6738 - val_accuracy: 0.6103 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6681 - accuracy: 0.5574 - val_loss: 0.6514 - val_accuracy: 0.7059 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6737 - accuracy: 0.5815 - val_loss: 0.6520 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6416 - accuracy: 0.6370 - val_loss: 0.6887 - val_accuracy: 0.5221 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6405 - accuracy: 0.6519 - val_loss: 0.6346 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6042 - accuracy: 0.6648 - val_loss: 0.6135 - val_accuracy: 0.6618 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5761 - accuracy: 0.6981 - val_loss: 0.6142 - val_accuracy: 0.6324 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.5752 - accuracy: 0.7037 - val_loss: 0.6027 - val_accuracy: 0.6691 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5404 - accuracy: 0.7389 - val_loss: 0.6136 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.5074 - accuracy: 0.7556 - val_loss: 0.6140 - val_accuracy: 0.6691 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.4802 - accuracy: 0.7704 - val_loss: 0.6135 - val_accuracy: 0.6912 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.4919 - accuracy: 0.7704 - val_loss: 0.6322 - val_accuracy: 0.6985 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4343 - accuracy: 0.7944 - val_loss: 0.6245 - val_accuracy: 0.6691 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.6219 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3976 - accuracy: 0.8352 - val_loss: 0.6270 - val_accuracy: 0.6912 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3897 - accuracy: 0.8148 - val_loss: 0.6411 - val_accuracy: 0.6985 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3592 - accuracy: 0.8315 - val_loss: 0.6269 - val_accuracy: 0.7279 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.3552 - accuracy: 0.8611 - val_loss: 0.6607 - val_accuracy: 0.7059 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3351 - accuracy: 0.8556 - val_loss: 0.6334 - val_accuracy: 0.7206 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3496 - accuracy: 0.8463 - val_loss: 0.6360 - val_accuracy: 0.7353 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3259 - accuracy: 0.8630 - val_loss: 0.6233 - val_accuracy: 0.7206 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3206 - accuracy: 0.8722 - val_loss: 0.6378 - val_accuracy: 0.6985 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3039 - accuracy: 0.8796 - val_loss: 0.6585 - val_accuracy: 0.7059 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2982 - accuracy: 0.8685 - val_loss: 0.6433 - val_accuracy: 0.7059 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2959 - accuracy: 0.8796 - val_loss: 0.6335 - val_accuracy: 0.7132 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2733 - accuracy: 0.8907 - val_loss: 0.6464 - val_accuracy: 0.6985 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2877 - accuracy: 0.8667 - val_loss: 0.6379 - val_accuracy: 0.6912 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2770 - accuracy: 0.9093 - val_loss: 0.6454 - val_accuracy: 0.7059 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2786 - accuracy: 0.8796 - val_loss: 0.6496 - val_accuracy: 0.7132 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2691 - accuracy: 0.8981 - val_loss: 0.6472 - val_accuracy: 0.7132 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2605 - accuracy: 0.8981 - val_loss: 0.6506 - val_accuracy: 0.7132 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2691 - accuracy: 0.8889 - val_loss: 0.6377 - val_accuracy: 0.6912 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2859 - accuracy: 0.8704 - val_loss: 0.6394 - val_accuracy: 0.6912 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2722 - accuracy: 0.8833 - val_loss: 0.6443 - val_accuracy: 0.7059 - lr: 3.1250e-05\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2657 - accuracy: 0.8907 - val_loss: 0.6526 - val_accuracy: 0.7059 - lr: 3.1250e-05\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2639 - accuracy: 0.8926 - val_loss: 0.6513 - val_accuracy: 0.7059 - lr: 3.1250e-05\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2777 - accuracy: 0.8926 - val_loss: 0.6527 - val_accuracy: 0.7059 - lr: 3.1250e-05\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2602 - accuracy: 0.8981 - val_loss: 0.6554 - val_accuracy: 0.7206 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2651 - accuracy: 0.8944 - val_loss: 0.6540 - val_accuracy: 0.7132 - lr: 1.5625e-05\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2582 - accuracy: 0.8870 - val_loss: 0.6545 - val_accuracy: 0.7132 - lr: 1.5625e-05\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2802 - accuracy: 0.9056 - val_loss: 0.6508 - val_accuracy: 0.7132 - lr: 1.5625e-05\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2647 - accuracy: 0.8926 - val_loss: 0.6509 - val_accuracy: 0.7059 - lr: 1.5625e-05\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2648 - accuracy: 0.8907 - val_loss: 0.6487 - val_accuracy: 0.7132 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2654 - accuracy: 0.8926 - val_loss: 0.6504 - val_accuracy: 0.7132 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2619 - accuracy: 0.9000 - val_loss: 0.6513 - val_accuracy: 0.7132 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2685 - accuracy: 0.8981 - val_loss: 0.6515 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2664 - accuracy: 0.8870 - val_loss: 0.6497 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2766 - accuracy: 0.8944 - val_loss: 0.6485 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2796 - accuracy: 0.8741 - val_loss: 0.6456 - val_accuracy: 0.7132 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2552 - accuracy: 0.8889 - val_loss: 0.6469 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2568 - accuracy: 0.8870 - val_loss: 0.6483 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2492 - accuracy: 0.8981 - val_loss: 0.6488 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2498 - accuracy: 0.9074 - val_loss: 0.6480 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.2611 - accuracy: 0.8944 - val_loss: 0.6474 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2653 - accuracy: 0.8907 - val_loss: 0.6476 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2694 - accuracy: 0.8907 - val_loss: 0.6475 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2543 - accuracy: 0.9074 - val_loss: 0.6473 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2630 - accuracy: 0.8833 - val_loss: 0.6474 - val_accuracy: 0.7206 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 7s 101ms/step - loss: 0.6977 - accuracy: 0.5178 - val_loss: 0.6835 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6893 - accuracy: 0.5402 - val_loss: 0.6756 - val_accuracy: 0.5597 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.6804 - accuracy: 0.5477 - val_loss: 0.6592 - val_accuracy: 0.6045 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6661 - accuracy: 0.5551 - val_loss: 0.6424 - val_accuracy: 0.6493 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6563 - accuracy: 0.6037 - val_loss: 0.6375 - val_accuracy: 0.6642 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6368 - accuracy: 0.6224 - val_loss: 0.6400 - val_accuracy: 0.6567 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.6371 - accuracy: 0.6075 - val_loss: 0.6013 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6191 - accuracy: 0.6430 - val_loss: 0.6039 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5975 - accuracy: 0.6692 - val_loss: 0.6094 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6122 - accuracy: 0.6280 - val_loss: 0.5793 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5891 - accuracy: 0.6766 - val_loss: 0.5478 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5799 - accuracy: 0.7047 - val_loss: 0.5331 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5616 - accuracy: 0.7065 - val_loss: 0.5509 - val_accuracy: 0.7388 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5601 - accuracy: 0.7121 - val_loss: 0.5438 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5313 - accuracy: 0.7252 - val_loss: 0.5433 - val_accuracy: 0.7313 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5189 - accuracy: 0.7383 - val_loss: 0.5131 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4814 - accuracy: 0.7738 - val_loss: 0.4985 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4643 - accuracy: 0.7551 - val_loss: 0.4865 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4417 - accuracy: 0.7944 - val_loss: 0.4686 - val_accuracy: 0.7910 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4150 - accuracy: 0.7907 - val_loss: 0.4892 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4108 - accuracy: 0.7944 - val_loss: 0.5126 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4003 - accuracy: 0.7981 - val_loss: 0.4508 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3849 - accuracy: 0.8393 - val_loss: 0.4702 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3721 - accuracy: 0.8280 - val_loss: 0.5088 - val_accuracy: 0.7761 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3494 - accuracy: 0.8449 - val_loss: 0.4318 - val_accuracy: 0.8134 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3206 - accuracy: 0.8430 - val_loss: 0.4363 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3367 - accuracy: 0.8486 - val_loss: 0.4587 - val_accuracy: 0.8134 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3144 - accuracy: 0.8617 - val_loss: 0.4696 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2987 - accuracy: 0.8579 - val_loss: 0.4685 - val_accuracy: 0.7463 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2696 - accuracy: 0.8766 - val_loss: 0.4841 - val_accuracy: 0.7836 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2684 - accuracy: 0.8729 - val_loss: 0.4872 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2525 - accuracy: 0.8935 - val_loss: 0.4834 - val_accuracy: 0.7761 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2849 - accuracy: 0.8673 - val_loss: 0.4966 - val_accuracy: 0.7537 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2367 - accuracy: 0.8953 - val_loss: 0.5067 - val_accuracy: 0.7612 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2005 - accuracy: 0.9140 - val_loss: 0.5423 - val_accuracy: 0.7537 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2244 - accuracy: 0.8935 - val_loss: 0.5042 - val_accuracy: 0.7537 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2179 - accuracy: 0.8935 - val_loss: 0.5052 - val_accuracy: 0.7687 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2082 - accuracy: 0.9140 - val_loss: 0.5021 - val_accuracy: 0.7612 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2021 - accuracy: 0.9065 - val_loss: 0.5107 - val_accuracy: 0.7687 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1723 - accuracy: 0.9271 - val_loss: 0.5137 - val_accuracy: 0.7687 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1843 - accuracy: 0.9121 - val_loss: 0.5206 - val_accuracy: 0.7687 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1837 - accuracy: 0.9252 - val_loss: 0.5408 - val_accuracy: 0.7612 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2300 - accuracy: 0.8991 - val_loss: 0.5227 - val_accuracy: 0.7463 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1783 - accuracy: 0.9290 - val_loss: 0.5131 - val_accuracy: 0.7537 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1783 - accuracy: 0.9140 - val_loss: 0.5111 - val_accuracy: 0.7612 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1754 - accuracy: 0.9178 - val_loss: 0.5131 - val_accuracy: 0.7537 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1726 - accuracy: 0.9290 - val_loss: 0.5145 - val_accuracy: 0.7537 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1614 - accuracy: 0.9402 - val_loss: 0.5247 - val_accuracy: 0.7537 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1529 - accuracy: 0.9477 - val_loss: 0.5220 - val_accuracy: 0.7612 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1573 - accuracy: 0.9327 - val_loss: 0.5181 - val_accuracy: 0.7612 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1578 - accuracy: 0.9458 - val_loss: 0.5194 - val_accuracy: 0.7612 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1521 - accuracy: 0.9383 - val_loss: 0.5237 - val_accuracy: 0.7463 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1711 - accuracy: 0.9252 - val_loss: 0.5237 - val_accuracy: 0.7463 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1602 - accuracy: 0.9383 - val_loss: 0.5263 - val_accuracy: 0.7537 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.1711 - accuracy: 0.9252 - val_loss: 0.5228 - val_accuracy: 0.7612 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1517 - accuracy: 0.9439 - val_loss: 0.5223 - val_accuracy: 0.7612 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1449 - accuracy: 0.9383 - val_loss: 0.5248 - val_accuracy: 0.7612 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.1644 - accuracy: 0.9364 - val_loss: 0.5228 - val_accuracy: 0.7612 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.1584 - accuracy: 0.9364 - val_loss: 0.5220 - val_accuracy: 0.7612 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.1505 - accuracy: 0.9327 - val_loss: 0.5211 - val_accuracy: 0.7537 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1671 - accuracy: 0.9327 - val_loss: 0.5207 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1615 - accuracy: 0.9402 - val_loss: 0.5207 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1759 - accuracy: 0.9234 - val_loss: 0.5214 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1548 - accuracy: 0.9383 - val_loss: 0.5224 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1783 - accuracy: 0.9383 - val_loss: 0.5223 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1491 - accuracy: 0.9327 - val_loss: 0.5223 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1538 - accuracy: 0.9290 - val_loss: 0.5205 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1528 - accuracy: 0.9346 - val_loss: 0.5202 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.1415 - accuracy: 0.9514 - val_loss: 0.5215 - val_accuracy: 0.7537 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1912 - accuracy: 0.9271 - val_loss: 0.5211 - val_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.1494 - accuracy: 0.9439 - val_loss: 0.5204 - val_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1512 - accuracy: 0.9383 - val_loss: 0.5203 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.1626 - accuracy: 0.9402 - val_loss: 0.5211 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1479 - accuracy: 0.9383 - val_loss: 0.5219 - val_accuracy: 0.7687 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.1496 - accuracy: 0.9402 - val_loss: 0.5222 - val_accuracy: 0.7612 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 10ms/step\n",
      "Processing file: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv\n",
      "Training for label: 未来7日涨幅\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 7s 100ms/step - loss: 0.7011 - accuracy: 0.4990 - val_loss: 0.6927 - val_accuracy: 0.4621 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6991 - accuracy: 0.5181 - val_loss: 0.6790 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6943 - accuracy: 0.5219 - val_loss: 0.6872 - val_accuracy: 0.5530 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6854 - accuracy: 0.5829 - val_loss: 0.6488 - val_accuracy: 0.6591 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6776 - accuracy: 0.5848 - val_loss: 0.6575 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6874 - accuracy: 0.5676 - val_loss: 0.6815 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6627 - accuracy: 0.6267 - val_loss: 0.6354 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6374 - accuracy: 0.6248 - val_loss: 0.6399 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6138 - accuracy: 0.6533 - val_loss: 0.6224 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.6035 - accuracy: 0.6610 - val_loss: 0.6236 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5908 - accuracy: 0.6876 - val_loss: 0.6058 - val_accuracy: 0.6364 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5592 - accuracy: 0.7162 - val_loss: 0.5912 - val_accuracy: 0.6591 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5629 - accuracy: 0.7010 - val_loss: 0.6150 - val_accuracy: 0.6818 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.5381 - accuracy: 0.7295 - val_loss: 0.6649 - val_accuracy: 0.6061 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5121 - accuracy: 0.7333 - val_loss: 0.5735 - val_accuracy: 0.7197 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5179 - accuracy: 0.7371 - val_loss: 0.6022 - val_accuracy: 0.6818 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4937 - accuracy: 0.7448 - val_loss: 0.5787 - val_accuracy: 0.6970 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5055 - accuracy: 0.7619 - val_loss: 0.5625 - val_accuracy: 0.7121 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4883 - accuracy: 0.7657 - val_loss: 0.5684 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4422 - accuracy: 0.8095 - val_loss: 0.5760 - val_accuracy: 0.7273 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4443 - accuracy: 0.8019 - val_loss: 0.5426 - val_accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.4345 - accuracy: 0.8114 - val_loss: 0.5503 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3824 - accuracy: 0.8381 - val_loss: 0.5542 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3979 - accuracy: 0.8248 - val_loss: 0.5853 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3809 - accuracy: 0.8190 - val_loss: 0.5793 - val_accuracy: 0.7803 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3574 - accuracy: 0.8648 - val_loss: 0.5471 - val_accuracy: 0.7652 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3554 - accuracy: 0.8590 - val_loss: 0.5583 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3231 - accuracy: 0.8610 - val_loss: 0.5627 - val_accuracy: 0.7955 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3420 - accuracy: 0.8476 - val_loss: 0.5405 - val_accuracy: 0.7879 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3110 - accuracy: 0.8667 - val_loss: 0.5633 - val_accuracy: 0.8106 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 1s 40ms/step - loss: 0.3116 - accuracy: 0.8629 - val_loss: 0.5531 - val_accuracy: 0.8106 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.3014 - accuracy: 0.8686 - val_loss: 0.5642 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2966 - accuracy: 0.8819 - val_loss: 0.5979 - val_accuracy: 0.7803 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.3116 - accuracy: 0.8571 - val_loss: 0.5583 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.3121 - accuracy: 0.8590 - val_loss: 0.5545 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2984 - accuracy: 0.8724 - val_loss: 0.5702 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2787 - accuracy: 0.8762 - val_loss: 0.5675 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2604 - accuracy: 0.8914 - val_loss: 0.5621 - val_accuracy: 0.7879 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2761 - accuracy: 0.8971 - val_loss: 0.5776 - val_accuracy: 0.7803 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2608 - accuracy: 0.9067 - val_loss: 0.5675 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2426 - accuracy: 0.8971 - val_loss: 0.5712 - val_accuracy: 0.8106 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.2479 - accuracy: 0.8914 - val_loss: 0.5834 - val_accuracy: 0.7955 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.2415 - accuracy: 0.9162 - val_loss: 0.5721 - val_accuracy: 0.7879 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2425 - accuracy: 0.9105 - val_loss: 0.5702 - val_accuracy: 0.8030 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2352 - accuracy: 0.8952 - val_loss: 0.5703 - val_accuracy: 0.7955 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2287 - accuracy: 0.9124 - val_loss: 0.5674 - val_accuracy: 0.8030 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2506 - accuracy: 0.9105 - val_loss: 0.5634 - val_accuracy: 0.8030 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2520 - accuracy: 0.8990 - val_loss: 0.5714 - val_accuracy: 0.7803 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2317 - accuracy: 0.9029 - val_loss: 0.5780 - val_accuracy: 0.8030 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2491 - accuracy: 0.9124 - val_loss: 0.5747 - val_accuracy: 0.7955 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2124 - accuracy: 0.9181 - val_loss: 0.5717 - val_accuracy: 0.7955 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2444 - accuracy: 0.9010 - val_loss: 0.5727 - val_accuracy: 0.7803 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2448 - accuracy: 0.8838 - val_loss: 0.5801 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2173 - accuracy: 0.9143 - val_loss: 0.5824 - val_accuracy: 0.7879 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2484 - accuracy: 0.9105 - val_loss: 0.5808 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.5810 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2542 - accuracy: 0.8876 - val_loss: 0.5823 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2258 - accuracy: 0.9124 - val_loss: 0.5825 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2451 - accuracy: 0.9048 - val_loss: 0.5808 - val_accuracy: 0.7879 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2114 - accuracy: 0.9105 - val_loss: 0.5813 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 0.2305 - accuracy: 0.9219 - val_loss: 0.5830 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.2377 - accuracy: 0.9029 - val_loss: 0.5841 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.2278 - accuracy: 0.9067 - val_loss: 0.5840 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2378 - accuracy: 0.9029 - val_loss: 0.5843 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2341 - accuracy: 0.9048 - val_loss: 0.5842 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2374 - accuracy: 0.9067 - val_loss: 0.5832 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 41ms/step - loss: 0.2227 - accuracy: 0.9067 - val_loss: 0.5832 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.5855 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2177 - accuracy: 0.9257 - val_loss: 0.5872 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2392 - accuracy: 0.9029 - val_loss: 0.5869 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2244 - accuracy: 0.9067 - val_loss: 0.5876 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2156 - accuracy: 0.9200 - val_loss: 0.5875 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2306 - accuracy: 0.9162 - val_loss: 0.5870 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.2271 - accuracy: 0.9086 - val_loss: 0.5867 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.2041 - accuracy: 0.9219 - val_loss: 0.5886 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2474 - accuracy: 0.9048 - val_loss: 0.5882 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2337 - accuracy: 0.9010 - val_loss: 0.5876 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2263 - accuracy: 0.9086 - val_loss: 0.5877 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.2435 - accuracy: 0.9067 - val_loss: 0.5878 - val_accuracy: 0.7879 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个数据集\n",
    "for file_path in file_paths:\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 特征和标签\n",
    "    features = data.iloc[:, 1:192]  # n1-n47, p1-p146\n",
    "    labels = {label: (data[label] > 0).astype(int) for label in label_columns}\n",
    "\n",
    "    # 标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Reshape data for LSTM input\n",
    "    features_scaled_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "    # 对每个标签进行训练和评估\n",
    "    for label_name, label_data in labels.items():\n",
    "        print(f\"Training for label: {label_name}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_scaled_reshaped, label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "        # 创建改进后的模型\n",
    "        model = create_cnn_lstm_6((features_scaled.shape[1], 1))\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "        # 预测并评估\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[label_name].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7529a8cb-312c-40df-a27c-a5d9e1d58a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_7.csv, Label: 未来7日涨幅, Accuracy: 0.6627\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_15.csv, Label: 未来7日涨幅, Accuracy: 0.7738\n",
      "File: C:\\Users\\mjy\\Desktop\\Project_MSCM\\INPUT_30.csv, Label: 未来7日涨幅, Accuracy: 0.8061\n"
     ]
    }
   ],
   "source": [
    "# 输出所有文件的准确率\n",
    "for label_name, accuracy_list in accuracies.items():\n",
    "    for i, accuracy in enumerate(accuracy_list):\n",
    "        print(f\"File: {file_paths[i]}, Label: {label_name}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42968f3f-a21e-4713-9eae-0a723a2868ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 数据\n",
    "categories = ['PAST 7 DAYS', 'PAST 15 DAYS', 'PAST 30 DAYS']\n",
    "adagrad = [0.5325, 0.5774, 0.6121]\n",
    "sgd = [0.6036, 0.6250, 0.6303]\n",
    "rmsprop = [0.6509, 0.7679, 0.7818]\n",
    "nadam = [0.6627, 0.7738, 0.8061]\n",
    "adamax = [0.6509, 0.7798, 0.8000]\n",
    "adam = [0.7515, 0.7619, 0.8242]\n",
    "\n",
    "# 设置柱状图的位置\n",
    "x = np.arange(len(categories))\n",
    "width = 0.13\n",
    "\n",
    "# 创建图形和轴\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# 绘制每种优化器的柱状图\n",
    "ax.bar(x - 2*width, adagrad, width, label='adagrad', color='orange')\n",
    "ax.bar(x - width, sgd, width, label='sgd', color='lightgreen')\n",
    "ax.bar(x, rmsprop, width, label='rmsprop', color='salmon')\n",
    "ax.bar(x + width, nadam, width, label='nadam', color='gold')\n",
    "ax.bar(x + 2*width, adamax, width, label='adamax', color='purple')\n",
    "ax.bar(x + 3*width, adam, width, label='adam', color='skyblue')\n",
    "\n",
    "# 添加标签和标题\n",
    "ax.set_xlabel('Time Span', fontsize=12)\n",
    "ax.set_ylabel('Performance', fontsize=12)\n",
    "ax.set_title('Model Performance Over Different Time Spans', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, fontsize=10)\n",
    "ax.legend()\n",
    "\n",
    "# 调整y轴范围\n",
    "ax.set_ylim(0.5, 0.85)\n",
    "\n",
    "# 显示网格\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8b19f-3f8d-4efd-a322-8061a1a7c1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
